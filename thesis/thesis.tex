\documentclass[a4paper,12pt]{report} % use options twoside, openright for print

\usepackage[a4paper]{geometry}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{graphicx}
\usepackage[]{hyperref} % use option hidelinks for print
\usepackage{enumitem}
\usepackage{epsfig}
\usepackage[italian]{babel}
\usepackage{setspace}
\usepackage{emptypage}
\usepackage{thesis}
\usepackage{subcaption}
\usepackage{parskip}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage{booktabs}
\usepackage[justification=centering]{caption}
\usepackage{nicematrix}
\usepackage[linesnumbered, ruled]{algorithm2e}
\usepackage[style=alphabetic,citestyle=alphabetic,backend=biber]{biblatex}
\usepackage{xurl}

% BIBLIOGRAPHY SETTINGS

\setcounter{biburllcpenalty}{7000}
\setcounter{biburlucpenalty}{8000}
\addbibresource{bibliography.bib}

% CUSTOM COMMANDS

\newcommand{\partitioned}[2]{#1\slash\!\!#2}  % partitioned set
\newcommand{\bigo}[0]{\mathcal{O}}            % big O notation

% THEOREMS ENVIRONMENTS

\newtheorem{theorem}{Teorema}[chapter]        % theorem
\newtheorem{definition}{Definizione}[chapter] % definition
\newtheorem{lemma}{Lemma}[chapter]            % lemma
\newtheorem{corollary}{Corollario}[theorem]   % corollary

% ALGORITHM ENVIRONMENT

\SetKwComment{Comment}{/* }{ */}  % comment style
\SetKwRepeat{DoWhile}{do}{while}  % do while loop
\SetKwInput{Input}{Parametri}
\SetKwInput{Output}{Output}
\newenvironment{algo}[3]{
  \IncMargin{1.3em}
  \begin{algorithm}
    \SetAlgorithmName{Algoritmo}{}{}
    \DontPrintSemicolon
    \caption{#1}
    \vspace{0.1em}
    \Indmm\Indmm
    \Input{#2}
    \Output{#3}
    \Indpp\Indpp
    \vspace{0.1em}
}{
  \end{algorithm}
  \DecMargin{1.3em}
}

% DOCUMENT

\begin{document}
% \raggedbottom with this the last line of the page is not aligned with the bottom of the page

% FRONTPAGE

\title{Iperminimizzazione di automi a stati finiti deterministici}
\author{Andrea TINELLI}
\dept{Corso di Laurea in Informatica} 
\anno{2023 - 2024}
\matricola{941800}
\relatore{Prof. Giovanni PIGHIZZINI}

% i think that this is not needed, but i have to verify
% with the professor, to re-enable it: remove the comment
% from the next line and from the thesis.sty file
% \correlatore{nome COGNOME}

% BLANK PAGE

\beforepreface
\prefacesection{}
{\hfill {\sl Questa pagina è stata lasciata intenzionalmente vuota.}}

% PREFACE

\prefacesection{Prefazione}
\addcontentsline{toc}{chapter}{Prefazione}

Nel campo dell'informatica teorica, uno degli argomenti di maggiore interesse è quello relativo alla 
teoria degli automi. All'interno di questo campo, sono studiate diverse tipologie di automi, tra i quali
figurano gli automi a stati finiti deterministici. Uno dei problemi di maggiore rilevanza che riguarda
questo tipo di automi è quello della minimizzazione. Tale problema consiste nel trovare un automa a stati finiti
deterministico che riconosca lo stesso linguaggio di un automa di partenza, ma con il minor numero di 
stati possibile. L'automa che soddisfa tali condizioni è detto minimo e, in generale, è unico.
Questo significa che, a meno di isomorfismi, non esiste un automa con un numero minore di stati che 
riconosca lo stesso linguaggio. Recentemente è stato introdotto un nuovo problema affine a quello
della minimizzazione, chiamato iperminimizzazione di automi a stati finiti deterministici. 
Questo problema consiste, dato un automa deterministico, nel trovare un automa a stati finiti
deterministico, detto iperminimo, con il minor numero di stati possibile che riconosca un linguaggio
finitamente differente rispetto al linguaggio riconosciuto dall'automa di partenza.
In altri termini, dato un automa iperminimo, un qualsiasi altro automa
con un numero minore di stati riconosce un linguaggio infinitamente differente rispetto al linguaggio
accettato dall'automa di partenza.
Contrariamente al problema della minimizzazione, l'automa iperminimo non è unico. È infatti possibile 
trovare più automi iperminimi per uno stesso automa di partenza, ciascuno dei quali
riconosce un linguaggio diverso finitamente differente rispetto a quello riconosciuto dall'automa di partenza.
L'iperminimizzazione risulta essere un problema di grande interesse teorico e pratico in quanto, in 
alcuni casi, permette di ridurre notevolmente il numero di stati dell'automa di partenza, anche rispetto
alla sua versione minimizzata. Il costo di questa riduzione consiste però nell'introduzione di un numero
finito di errori, cioè di stringhe su cui la risposta dell'automa iperminimo è sbagliata rispetto a quella
che sarebbe stata fornita dall'automa di partenza.
Negli ultimi anni la ricerca di algoritmi efficienti per la soluzione del problema dell'iperminimizzazione
è stata oggetto di studio. Nel corso del tempo sono emersi principalmente 
tre algoritmi per la risoluzione del problema, ciascuno dei quali rifinisce le strategie utilizzate migliorando
la complessità computazionale dell'algoritmo precedente. Il primo algoritmo presentato in grado di risolvere
il problema dell'iperminimizzazione in tempo polinomiale è stato quello di Badr, Geffert e Shipman \parencite{BGS09}, con 
complessità computazionale pari a $\bigo(n^3)$, dove $n$ è il numero di stati dell'automa di partenza.
Successivamente, sono stati proposti due nuovi algoritmi, l'algoritmo di Badr \parencite{Badr}, con complessità
computazionale $\bigo(n^2)$, e l'algoritmo di Holzer e Maletti \parencite{HM10}, con complessità computazionale 
uguale a $\bigo(n \log n)$. In questo elaborato vengono indagate le prestazioni di questi
algoritmi nel tentativo di stabilire un ponte tra la teoria e la pratica. Gli algoritmi sono stati
dunque implementati e sono stati condotti dei test per valutarne le presentazioni.
I risultati degli esperimenti svolti mostrano come l'algoritmo di Holzer e Maletti sia il più efficiente tra quelli proposti, 
in accordo con quanto previsto dalla teoria. Più sorprendentemente invece l'algoritmo di Badr, Geffert e Shipman, 
nonostante abbia una complessità computazionale maggiore rispetto all'algoritmo di Badr, 
si comporta in media meglio nella pratica in quanto il caso peggiore si verifica molto di rado.

L'elaborato è organizzato come segue:
\begin{itemize}
  \item nel Capitolo 1 sono presentate le nozioni preliminari, necessarie alla comprensione dell'elaborato,
  riguardanti la teoria degli automi;
  \item nel Capitolo 2 sono esposti il problema dell'iperminimizzazione di automi a stati finiti deterministici
  ed i diversi algoritmi proposti per la sua risoluzione;
  \item nel Capitolo 3 sono fornite delle possibili implementazioni degli algoritmi di iperminimizzazione
  presentati nel capitolo precedente;
  \item nel Capitolo 4 sono discussi i risultati sperimentali ottenuti dagli esperimenti condotti per la valutazione
  delle prestazioni degli algoritmi di iperminimizzazione nella pratica.
\end{itemize}

% THANKS TO

\prefacesection{Ringraziamenti}
\addcontentsline{toc}{chapter}{Ringraziamenti}

Prima di tutto, voglio ringraziare il mio relatore, Prof. Giovanni Pighizzini,
per la sua guida e il suo supporto durante questo progetto.

Voglio inoltre esprimere la mia gratitudine verso la mia famiglia, in particolare ai miei genitori, per 
tutto quello che hanno fatto affinchè potessi intraprendere questo percorso e durante 
il quale mi hanno sempre fornito il loro pieno supporto ed incoraggiamento.
Ci tengo anche a ringraziare la mia fidanzata, Beatrice, per essere sempre stata al mio fianco
e per avermi stimolato a proseguire e ad impegnarmi al massimo.

Desidero infine manifestare la mia più sincera riconoscenza agli amici che mi hanno accompagnato durante
questo percorso accademico. Un primo ringraziamento va ai miei colleghi universitari, la cui collaborazione
e il cui supporto sono stati preziosi per il mio sviluppo scolastico e professionale. 
Allo stesso tempo, vorrei estendere i miei ringraziamenti agli amici di lunga data con i quali,
pur non condividendo direttamente il mio percorso universitario, ho passato momenti di svago e leggerezza
che mi hanno aiutato a mantenere l'equilibrio e la motivazione.

A tutti loro va il mio più sentito ringraziamento per aver contribuito, ciascuno a suo modo, 
al compimento di questo importante capitolo della mia vita.

\hfill \today

% TABLE OF CONTENTS

\afterpreface

% CHAPTER 1

\chapter{Nozioni preliminari}
\label{cap1}

La teoria degli automi è uno dei principali e più antichi campi dell'informatica teorica. In questo capitolo
ne vengono presentati i concetti fondamentali. Per un'esposizione più completa il lettore è rimandato a \parencite{HMU06}.

\section{Alfabeti, parole e linguaggi}

Un \emph{alfabeto}, generalmente indicato con la lettera $\Sigma$, è un insieme finito di simboli,
entità astratte non definite formalmente cui esempi possono essere lettere e cifre.

Una \emph{parola} (o \emph{stringa}) è una sequenza finita di simboli giustapposti, in particolare, una parola su un alfabeto $\Sigma$
è una sequenza finita di simboli appartenenti a $\Sigma$.

La \emph{lunghezza di una parola} $w$, indicata con $|w|$, è il numero di simboli che la compongono.
Caso particolare è la parola vuota, a cui per convenzione si fa riferimento con la lettera $\varepsilon$,
composta da zero simboli ($|\varepsilon| = 0$).

Un possibile esempio di alfabeto è $\Sigma = \{0, 1\}$, mentre una possibile parola su $\Sigma$ è
$w = 01$, dove $|w| = 2$.

Si è in grado a questo punto di introdurre il concetto di linguaggio.

\begin{definition}\label{def:lang}
  Un \emph{linguaggio} $L$ su un alfabeto $\Sigma$ è un insieme di parole su $\Sigma$, ovvero, un insieme di
  parole formate dalla giustappozione di simboli appartenenti a $\Sigma$.
\end{definition}

Due esempi particolari possono essere il linguaggio vuoto $L_\varnothing = \varnothing$ ed il linguaggio composto
solo dalla parola vuota $L_\varepsilon = \{\varepsilon\}$, puntualizzando il fatto che $L_\varnothing \neq L_\varepsilon$,
infatti $||L_\varnothing|| = 0$ mentre $||L_\varepsilon|| = 1$.

Convenzionalmente, fissato un alfabeto $\Sigma$, viene indicato con $\Sigma^*$ il linguaggio composto da tutte
le parole su $\Sigma$, compresa la parola vuota.

Sia $\Sigma = \{a, b\}$, allora $\Sigma^* = \{\varepsilon, a, b, aa, ab, ba, bb, aaa, \dots\}$.

\section{Automi a stati finiti}

In generale, un automa è un modello matematico di una macchina che esegue delle operazioni predefinite.

Una delle principali tipologie di automi è quella degli automi a stati finiti (FSA). Questi, sono sistemi
con un numero finito di input, che possono trovarsi in un numero finito di configurazioni interne chiamate stati. 
In questa categoria rientrano gli automi a stati finiti deterministici (DFA) e gli automi a stati finiti 
non deterministici (NFA).

\begin{definition}
  \label{def:dfa}
  Un \emph{automa a stati finiti deterministico} è una quintupla $A = (Q, \Sigma, \delta, \allowbreak q_I, F)$
  dove $Q$ denota un insieme finito di stati, $\Sigma$ un alfabeto, $\delta: Q \times \Sigma \rightarrow Q$ 
  la funzione di transizione, $q_I \in Q$ lo stato iniziale e $F \subseteq Q$ l'insieme degli stati finali.
\end{definition}

La funzione di transizione $\delta$ può essere estesa per essere applicata a parole. Si definisce dunque
$\hat{\delta}: Q \times \Sigma^* \rightarrow Q$ dove $\hat{\delta}(q, w)$ è lo stato in cui l'automa si trova,
partendo dallo stato $q$, dopo aver letto la parola $w$. Più formalmente, $\hat{\delta}(q, \varepsilon) = q$ e
$\hat{\delta}(q, w\sigma) = \delta(\hat{\delta}(q, w), \sigma)$ per ogni $w \in \Sigma^*$ e $\sigma \in \Sigma$.

Una comune rappresentazione della funzione di transizione è quella in forma tabellare, chiamata tabella di transizione,
nella quale le righe corrispondono agli stati, le colonne ai possibili simboli in ingresso ed il generico elemento
di riga $q$ e colonna $\sigma$ allo stato $\delta(q, \sigma)$. Lo stato iniziale e gli stati finali sono evidenziati
rispettivamente con $\rightarrow$ e $*$.

Generalmente, gli automi a stati finiti vengono rappresentanti graficamente attraverso grafi orientati.
In tale rappresentazione gli archi corrispondono alle transizioni e i nodi agli stati, tra i quali, lo stato iniziale è
evidenziato con un arco in ingresso privo di origine mentre gli stati finali sono evidenziati con un doppio cerchio.

Un esempio di automa a stati finiti deterministico è mostrato in Figura \ref{fig:dfa}, in tale caso,
$Q = \{A, B, C, D, E, F, G, H\}$, $\Sigma = \{a, b\}$, $q_I = A$ e $F = \{E, G, H\}$, mentre
la funzione di transizione $\delta$ è mostrata in Tabella \ref{tab:transitions}.

\begin{definition}
  \label{def:reg-lang}
  Sia $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico, si definisce il \emph{linguaggio
  riconosciuto} da $A$ come $L(A) = \{w \in \Sigma^* \mid \hat{\delta}(q_I, w) \in F\}$, ovvero, come
  il linguaggio composto da tutte le parole $w \in \Sigma^*$ che portano dallo stato iniziale $q_I$ ad
  uno stato $q \in F$.
\end{definition}

Gli automi a stati finiti non deterministici sono simili ai DFA, la differenza principale risiede nella
funzione di transizione che è definita come $\delta: Q \times \Sigma \rightarrow 2^Q$ che ne cambia di
conseguenza anche il modo di elaborare gli input. In questo modo, partendo dallo stato iniziale e leggendo
una parola $w$ è possibile raggiungere più stati. La parola è accettata se almeno uno degli stati raggiunti è
finale.

Data la non rilevanza degli NFA per il proseguo della trattazione, maggiori dettagli, per i quali il lettore è
nuovamente rimandato a \parencite{HMU06}, sono omessi. Si ritiene tuttavia importante puntualizzare come gli automi
a stati finiti non deterministici siano equivalenti a quelli deterministici, ovvero, per ogni NFA esiste un
DFA che riconosce lo stesso linguaggio e viceversa.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.7\linewidth]{images/dfa.png}
  \caption{\label{fig:dfa}Un esempio di automa a stati finiti deterministico.}
\end{figure}

\begin{table}[!htb]
  \centering
  \begin{tabular}{r|c|c}
    \toprule
                      & $a$ & $b$ \\
    \midrule
    $\rightarrow A$   & $B$ & $C$ \\
    $B$               & $E$ & $D$ \\
    $C$               & $D$ & $F$ \\
    $D$               & $H$ & $G$ \\
    $*E$              & $F$ & $H$ \\
    $F$               & $E$ & $G$ \\
    $*G$              & $G$ & $H$ \\
    $*H$              & $H$ & $H$ \\
    \bottomrule
  \end{tabular}
  \caption{\label{tab:transitions}Tabella di transizione dell'automa in Figura \ref{fig:dfa}.}
\end{table}

\section{Minimizzazione di DFA}
\label{min-dfa}

Uno dei problemi di maggiore interesse nel campo della teoria degli automi è quello riguardante la minimizzazione di 
automi a stati finiti deterministici. Il problema consiste, dato un automa $A = (Q, \Sigma, \delta, q_I, F)$,
nel trovare un automa $A' = (Q', \Sigma, \delta', q_I', F')$ tale che $L(A') = L(A)$ e $||Q'||$ sia minimo.

Il concetto alla base della minimizzazione è quello di equivalenza tra stati:

\begin{definition}
  \label{def:eq-states}
  Due stati $q_A$ e $q_B$ sono detti \emph{equivalenti}, denotato con $q_A \equiv q_B$, 
  se $\forall w \in \Sigma^*$, $\hat{\delta}(q_A, w) \in F$ se e solo se $\hat{\delta}(q_B, w) \in F$.
  Specularmente, due stati $q_A$ e $q_B$ non equivalenti sono detti distinguibili.
\end{definition}

\begin{theorem}
  \label{th:eq-rel-states}
  "$\equiv$" è una relazione di equivalenza, ovvero, è riflessiva, simmetrica e transitiva.
\end{theorem}

L'importanza dell'equivalenza tra stati è evidente nel momento in cui si considera che
due stati equivalenti, possono essere sostituiti da un singolo stato che si comporti come entrambi.
La diretta conseguenza risiede nel fatto che, dato un automa di partenza $A = (Q, \Sigma, \delta, q_I, F)$, 
siano $q_A, q_B \in Q$ tali che $q_A \equiv q_B$, è possibile costruire un automa $A' = (Q', \Sigma, \delta', q_I', F')$,
con $||Q'|| < ||Q||$ e $L(A') = L(A)$, facendo collassare gli stati $q_A$ e $q_B$ in un singolo stato $q'$, ovvero, definendo
$Q' = Q \setminus \{q_A, q_B\} \cup \{q'\}$ e la funzione di transizione $\delta'$
in modo che tutte le transizioni in ingresso a $q_A$ e $q_B$ vengano reindirizzate a $q'$ e che
$\delta'(q', \sigma) = \delta(q_A, \sigma)$ per ogni $\sigma \in \Sigma$, prestando particolare attenzione,
se necessario, anche alla conseguente ridefinizione dello stato iniziale e degli stati finali in $A'$.

Il Teorema \ref{th:eq-rel-states} permette di estendere il risultato sopra riportato ad un numero arbitrario di
stati equivalenti. Più formalmente, siano $q_1, q_2, \dots, q_n \in Q$ con $n \in \mathbb{N}$ tali che
$q_1 \equiv q_2 \equiv \dots \equiv q_n$, allora è possibile collassare gli stati $q_1, q_2, \dots, q_n$ in un
singolo stato $q'$ mantenendo il linguaggio riconosciuto dall'automa inalterato.

Grazie all'idea di equivalenza tra stati, è possibile definire l'equivalenza tra automi: siano
$A_1 = (Q_1, \Sigma, \delta_1, q_{I_1}, F_1)$ e $A_2 = (Q_2, \Sigma, \delta_2, q_{I_2}, F_2)$ due DFA, 
$A_1$ è detto \emph{equivalente} ad $A_2$, denotato con $A_1 \equiv A_2$, se $q_{I_1} \equiv q_{I_2}$.
É banale osservare che, se $A_1 \equiv A_2$, questi accettano gli stessi input, pertanto $L(A_1) = L(A_2)$.

Ricordando inoltre che una classe di equivalenza è un sottoinsieme della partizione $P$ di un insieme $S$ determinata da
una relazione di equivalenza $R$ su $S$ \parencite{Ros18}, si introduce il concetto di \emph{insieme quoziente},
denotato da $S \slash R$, come l'insieme delle classi di equivalenza di $R$ su $S$.

\begin{theorem}
  \label{th:min-dfa}
  Sia $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico, $A$ è detto \emph{minimo}
  (o \emph{minimizzato}) se non esiste un automa $A' = (Q', \Sigma, \delta', q_I', F')$ tale che $A \equiv A'$ e $||Q'|| < ||Q||$.
\end{theorem}

Queste nozioni permettono di fornire quella che è la soluzione al problema della minimizzazione di automi a
stati finiti deterministici.

Dato un automa $A = (Q, \Sigma, \delta, q_I, F)$, l'automa $A' = (Q', \Sigma, \delta', q_I', F')$ ottenuto, dapprima
rimuovendo gli stati irraggiungibili in $A$, e successivamente $\forall Q_i \in \partitioned{Q}{\equiv}$ collassando gli stati
in $Q_i$ in un singolo stato $q_i \in Q_i$ scelto arbitrariamente, è equivalente ad $A$ e $||Q'||$ è minimo.
$A'$ corrisponde quindi all'automa $A$ minimizzato.

\begin{theorem}
  \label{th:unique-min-dfa}
  L'automa minimo $A'$ ottenuto come descritto sopra è unico, questo significa che a meno di isomorfismi,
  non esiste un automa $A''$ tale che $A'' \equiv A'$ e $A'' \neq A'$.
\end{theorem}

Prendendo come esempio l'automa in Figura \ref{fig:dfa}, si procede alla sua minimizzazione seguendo
la procedura sopra descritta. L'automa risulta essere privo di stati irraggiungibili,
pertanto si procede da subito con il calcolo del partizionamento di $Q$ in classi di equivalenza,
che risulta essere
$\partitioned{Q}{\equiv} \ = \{ \{A\}, \{B\}, \{C\}, \{D\}, \{E\}, \{F\}, \{G, H\}\}$.
Si passa quindi al collasso degli stati, in particolare, gli unici stati equivalenti risultano essere
$G$ e $H$ che vengono sostituiti da un unico stato $G$, ottenendo l'automa in Figura \ref{fig:minified-dfa}.

In ultima istanza, si sottolinea come sia ben noto un algoritmo per la minimizzazione di automi a stati 
finiti deterministici, l'algoritmo di Hopcroft \parencite{Hop71}, che permette, partendo da un DFA in ingresso, 
di ottenere l'automa minimo in tempo $\bigo(n \log n)$.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.7\linewidth]{images/minified_dfa.png}
  \caption{\label{fig:minified-dfa}L'automa in Figura \ref{fig:dfa} minimizzato.}
\end{figure}

% CHAPTER 2

\chapter{Iperminimizzazione di DFA}
\label{cap2}

\section{Introduzione}

Recentemente è stato introdotto un nuovo problema, affine a quello della minimizzazione, chiamato
iperminimizzazione di automi a stati finiti deterministici \parencite{BGS09}.

Il problema dell'iperminimizzazione può essere visto come un'estensione del problema della minimizzazione: dove la
minimizzazione permette di ridurre al minimo il numero di stati di un DFA mantenendo inalterato il linguaggio
riconosciuto, l'imperminimizzazione prevede un'ulteriore riduzione al minimo numero di stati mantenendo invece
finita la differenza simmetrica tra il linguaggio riconosciuto dall'automa originale e quello riconosciuto
dall'automa ottenuto.

\begin{definition}\label{def:f-equiv}
  Due linguaggi $L_1$ e $L_2$ sono detti \emph{finitamente equivalenti} (o \emph{f-equivalenti}), denotato con
  $L_1 \sim L_2$, se $L_1 \Delta L_2$ è un insieme finito, dove $L_1 \Delta L_2$ denota la differenza
  simmetrica tra i linguaggi.
\end{definition}

Più formalmente dunque, dato un DFA $A = (Q, \Sigma, \delta, q_I, F)$,
l'iperminimizzazione consiste nel trovare un automa $A' = (Q', \Sigma, \delta', q_I', F')$ tale
che $L(A') \sim L(A)$ e $||Q'||$ sia minimo.

\section{Classi di quasi-equivalenza}
\label{sec:aeq-classes}

Analogamente al concetto classico di minimizzazione, in cui è di centrale rilevanza l'equivalenza tra stati,
è necessario introdurre la nozione di quasi-equivalenza tra stati per poter affrontare il problema
dell'iperminimizzazione.

\begin{definition}\label{th:aeq-states}
  Due stati $q_A$ e $q_B$ sono detti \emph{quasi-equivalenti}, denotato con $q_A \sim q_B$, 
  se $\exists k \in \mathbb{N}$, con $k \ge 0$, tale che $\forall w \in \Sigma^*$ di lunghezza $|w| \ge k$,
  $\hat{\delta}(q_A, w) \in F$ se e solo se $\hat{\delta}(q_B, w) \in F$.
\end{definition}

\begin{theorem}\label{th:aeq-rel-states}
  "$\sim$" è una relazione di equivalenza, ovvero, è riflessiva, simmetrica e transitiva.
\end{theorem}

Si introduce inoltre un importante risultato relativo alla quasi-equivalenza tra stati:

\begin{lemma}\label{lem:aeq-states}
  $q_A \sim q_B \Leftrightarrow \forall \sigma \in \Sigma, \delta(q_A, \sigma) \sim \delta(q_B, \sigma)$
\end{lemma}

Risulta evidente dunque come, grazie al Teorema \ref{th:aeq-rel-states}, sia possibile partizionare l'insieme 
degli stati $Q$ di un automa a stati finiti deterministico $A = (Q, \Sigma, \delta, q_I, F)$ in classi di quasi 
equivalenza e costruire dunque l'insieme quoziente $\partitioned{Q}{\sim}$.

Nell'automa $A = (Q, \Sigma, \delta, q_I, F)$ riportato in Figura \ref{fig:minified-dfa}, ad esempio, 
partizionando l'insieme degli stati $Q$ in classi di quasi-equivalenza, si ottiene l'insieme quoziente 
$\partitioned{Q}{\sim} \ = \{ \{ A \}, \{ C \}, \{ D, G \}, \{ F, B \}, \{ E \} \}$.

Equivalentemente a quanto visto per l'equivalenza tra stati, è possibile estendere il concetto di quasi-equivalenza
tra stati agli automi: due automi $A_1 = (Q_1, \Sigma, \delta_1,\allowbreak q_{I_1}, F_1)$ e 
$A_2 = (Q_2, \Sigma, \delta_2, q_{I_2}, F_2)$ sono detti \emph{quasi-equivalenti}, denotato con $A_1 \sim A_2$,
se $q_{I_1} \sim q_{I_2}$. Si osservi come, se $A_1 \sim A_2$, allora $L(A_1) \sim L(A_2)$.

Grazie al concetto di quasi-equivalenza tra automi, è ora possibile fornire la
definizione formale di automa a stati finiti deterministico iperminimo.

\begin{definition}\label{def:hyper-min-dfa}
  Sia $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico, $A$ è detto \emph{iperminimo}
  (o \emph{iperminimizzato}) se non esiste un automa $A' = (Q', \Sigma, \delta', q_I', F')$ tale che $A \sim A'$
  e $||Q'|| < ||Q||$.
\end{definition}

\section{Stati preambolo e kernel}
\label{sec:preamble-kernel}

Dato un automa a stati finiti deterministico $A = (Q, \Sigma, \delta, q_I, F)$, è importante, come ulteriore
passo verso la risoluzione del problema dell'iperminimizzazione, distinguere le diverse tipologie di stati 
che possono essere presenti in $A$.

È possibile partizionare l'insieme degli stati $Q$ di $A$ in tre parti: l'insieme degli stati irraggiungibili $U(A)$, 
l'insieme degli stati preambolo $P(A)$ e l'insieme degli stati kernel $K(A)$.

Sorvolando sulla definizione formale degli stati irraggiungibili, ben nota e non di centrale importanza per
la trattazione, viene fornita di seguito la definizione degli stati preambolo e kernel.

\begin{definition}\label{def:preamble-state}
  Uno stato $q \in Q$ è detto \emph{stato preambolo} e dunque $q \in P(A)$, se esiste almeno una parola in 
  ingresso $w \in \Sigma^*$ tale che $\hat{\delta}(q_I, w) = q$, ma il numero di tali stringhe è finito.
  In altri termini, $q$ è raggiungibile solo da un numero finito di input a partire dallo stato iniziale.
\end{definition}

\begin{definition}\label{def:kernel-state}
  Uno stato $q \in Q$ è detto \emph{stato kernel} e dunque $q \in K(A)$, se esistono infinite parole, tutte differenti tra loro, 
  in ingresso $w \in \Sigma^*$ tali che $\hat{\delta}(q_I, w) = q$.
  In altri termini, $q$ è raggiungibile da un numero infinito di input a partire dallo stato iniziale.
\end{definition}

\begin{lemma}\label{lem:kernel-state}
  Uno stato $q_A \in Q$ è in $K(A)$ se e solo se può essere raggiunto dallo stato iniziale $q_I$ attraverso
  un cammino passante per uno stato $q_B \in Q$ tale che esiste un ciclo in $A$ che inizia e termina in $q_B$.
\end{lemma}

Nell'automa $A$ riportato in Figura \ref{fig:minified-dfa}, ad esempio, è possibile osservare come gli stati 
$A$, $B$, $C$ e $D$ siano stati preambolo mentre gli stati $F$, $G$ ed $E$ siano stati kernel, o ancora, come
$P(A) = \{ A, B, C, D \}$ e $K(A) = \{ F, G, E \}$.

Si sottolinea un'importante differenza nel parallelismo tra automa minimo ed iperminimo: l'automa iperminimo
non è necessariamente unico. Si possono trovare esempi in cui un automa minimo $A'$ con $n$ stati può essere 
sostituito da diversi automi iperminimi differenti, tutti con il medesimo numero di stati $m \le n$,
ciascuno dei quali accetta un diverso linguaggio $L$ f-equivalente a $L(A')$. Tali automi possono tuttavia
differire solo per le transizioni in uscita da uno stato preambolo e in ingresso ad uno stato kernel, per i
valori accettati dagli stati preambolo, o per gli stati iniziali. In particolare, i kernel di due automi
iperminimi quasi-equivalenti sono isomorfi secondo la definizione
classica mentre i preamboli sono isomorfi, eccetto per i valori accettati.

\begin{definition}[Isomorfismo tra kernel]\label{def:kernel-isomorphism}
  Siano $A_1 = (Q_1, \Sigma, \delta_1, q_{I_1}, F_1)$ e $A_2 = (Q_2, \Sigma, \delta_2, q_{I_2}, F_2)$ due DFA,
  $A_1$ e $A_2$ hanno kernel isomorfi, denotato $A_1 \sim_K A_2$,
  se esiste una corrispondenza biunivoca $h: K(A_1) \rightarrow K(A_2)$ tale che:
  \begin{enumerate}[label=(\alph*)]
    \item $\forall q \in K(A_1)$ e $\forall \sigma \in \Sigma$, $h(\delta_1(q, \sigma))
    = \delta_2(h(q), \sigma)$;
    \item $\forall q \in K(A_1)$, $h(q) \in F_2$ se e solo se $q \in F_1$;
  \end{enumerate}
\end{definition}

\begin{theorem}\label{th:kernel-isomorphism}
  Siano $A_1$ e $A_2$ due automi minimi quasi-equivalenti, allora i loro kernel sono isomorfi ($A_1 \sim_K A_2$).
\end{theorem}

\begin{definition}[Isomorfismo tra preamboli]\label{def:preamble-isomorphism}
  Siano $A_1 = (Q_1, \Sigma, \delta_1, q_{I_1}, F_1)$ e $A_2 = (Q_2, \Sigma, \delta_2, q_{I_2}, F_2)$ due DFA,
  $A_1$ e $A_2$ hanno preamboli isomorfi, denotato $A_1 \sim_P A_2$,
  se esiste una corrispondenza biunivoca $h: P(A_1) \rightarrow P(A_2)$ tale che 
  $\forall q_{A}, q_{B} \in P(A_1)$ e $\forall \sigma \in \Sigma$ tali che $\delta_1(q_{A}, \sigma) = q_{B}$
  si ha che $\delta_2(h(q_{A}), \sigma) = h(q_{B})$.
\end{definition}

\begin{theorem}\label{th:preamble-isomorphism}
  Siano $A_1$ e $A_2$ due automi iperminimi quasi-equivalenti, allora i loro preamboli sono isomorfi ($A_1 \sim_P A_2$).
\end{theorem}

\section{Strategia generale}
\label{sec:hyperminimization-strategy}

Grazie alle nozioni presentate nelle Sezioni \ref{sec:aeq-classes} e \ref{sec:preamble-kernel}, è possibile
presentare una strategia generale per l'iperminimizzazione di automi a stati finiti deterministici.

Dato un automa $A = (Q, \Sigma, \delta, q_I, F)$, la procedura generale per l'iperminimizzazione consiste nel:
\begin{enumerate}
  \item ottenere l'automa minimo $A' = (Q', \Sigma, \delta', q_I', F')$ minimizzando classicamente $A$;
  \item identificare l'insieme degli stati preambolo $P(A')$ e degli stati kernel $K(A')$;
  \item determinare le classi di quasi-equivalenza su $Q'$ e costruire l'insieme $\partitioned{Q'}{\sim}$;
  \item $\forall Q_i \in \partitioned{Q'}{\sim}$ tale che $||Q_i|| > 1$ ed $\exists q_{i_1} \in Q_i$ tale che $q_{i_1} \in P(A')$:
  \begin{enumerate}
    \item se $\exists q_{i_2} \in Q_i$ tale che $q_{i_2} \in K(A')$, $\forall q \in Q_i \cap P(A')$ si collassa $q$ in $q_{i_2}$,
    \item altrimenti, tutti gli stati in $Q_i \setminus \{q_{i_1}\}$ sono collassati in $q_{i_1}$.
  \end{enumerate}
\end{enumerate}

L'automa $A''$ così ottenuto è l'automa iperminimo.

\begin{theorem}[Caratterizzazione di un DFA iperminimo]
  \label{th:char-hyper-min-dfa}
  Un automa a stati finiti deterministico $A = (Q, \Sigma, \delta, q_I, F)$ è iperminimo se e solo se:
  \begin{enumerate}[label=(\alph*)]
    \item $A$ è minimo
    \item non esiste una coppia di stati $q_A, q_B \in Q$ tali che $q_A \neq q_B$, $q_A \sim q_B$ e almeno uno dei due sia in $P(A)$
  \end{enumerate}
\end{theorem}

Si osservi che il primo passo della procedura, ovvero la minimizzazione dell'automa, permette di garantire 
che l'automa minimo ottenuto $A'$, sia privo di stati irraggiungibili ($U(A') = \emptyset$) e che quindi nei passaggi
successivi della strategia l'insieme degli stati possa essere partizionato
esclusivamente in due parti, gli stati preambolo e gli stati kernel ($Q' = P(A') \cup K(A')$).

Prendendo ancora una volta come esempio l'automa $A = (Q, \Sigma, \delta, q_I, F)$ in Figura \ref{fig:dfa},
si procede alla sua iperminimizzazione seguendo la strategia generale appena descritta.
La minimizzazione dell'automa, discussa in precedenza, porta all'automa minimo $A' = (Q', \Sigma, \delta', q_I', F')$
in Figura \ref{fig:minified-dfa}.
Ricordando ora che $P(A') = \{ A, B, C, D \}$, $K(A') = \{ F, G, E \}$ e che 
$\partitioned{Q'}{\sim} \ = \{ \{ A \}, \{ C \}, \{ D, G \}, \{ F, B \}, \{ E \} \}$,
si procede con il collasso degli stati:
\begin{enumerate}[label=--]
  \item essendo $D \sim G$, $D \in P(A')$ e $G \in K(A')$, si collassa $D$ in $G$
  \item essendo $F \sim B$, $B \in P(A')$ e $F \in K(A')$, si collassa $B$ in $F$
\end{enumerate}
ottenendo l'automa $A''$ iperminimo in Figura \ref{fig:hyper-minified-dfa}.

\begin{figure}[hbt!]
  \centering
  \includegraphics[width=0.7\linewidth]{images/hyper_minified_dfa.png}
  \caption{\label{fig:hyper-minified-dfa}L'automa in Figura \ref{fig:minified-dfa} iperminimizzato.}
\end{figure}

\section{Algoritmi}

Nel corso degli anni sono emersi diversi algoritmi per l'iperminimizzazione di automi a stati finiti deterministici,
ciascuno della quali, cambiando e/o raffinando le metodologie di identificazione degli stati preambolo, degli 
stati kernel e delle classi di quasi-equivalenza, e come queste siano manipolate, ha portato a differenti risultati,
migliorando la complessità temporale dei precendenti. Tutti gli algoritmi presentati di seguito condividono lo schema
ad alto livello riportato nella Sezione \ref{sec:hyperminimization-strategy} per poi specializzarsi,
in maniera differente, sulle strategie utilizzate per portare a termine le singole operazioni.

Si porta all'attenzione del lettore come, da qui in seguito, detto $A = (Q, \Sigma, \delta, q_I, F)$
l'automa in ingresso ad un algoritmo di iperminimizzazione, si utilizzerà $n$ per fare riferimento
al numero di stati $||Q||$ ed $m$ per il numero di simboli in ingresso $||\Sigma||$.

\subsection{Algoritmo di Badr, Geffert e Shipman}

L'algoritmo di Badr, Geffert e Shipman \parencite{BGS09} è stato il primo algoritmo proposto per l'iperminimizzazione
in grado, dato un automa $A = (Q, \Sigma, \delta, q_I, F)$, di ottenere l'automa iperminimo 
$A'' = (Q'', \Sigma, \delta'', q_I'', F'')$ in tempo polinomiale.

Come primo passo, l'algoritmo minimizza l'automa in ingresso $A$ ottenendo l'automa minimo 
$A' = (Q', \Sigma, \delta', q_I', F')$ attraverso l'algoritmo di Hopcroft.

Successivamente, viene costruita una matrice $E$ di dimensione $||Q'|| \times ||Q'||$, utilizzata nel
passo successivo per semplificare la fase di identificazione degli insiemi $P(A')$ e $K(A')$, tale che:
\begin{equation*}
  e_{i,j} =
  \begin{cases}
    1 & \text{se } \exists w \in \Sigma^* \setminus \{ \varepsilon \} \text{ tale che } \hat{\delta}(q_i, w) = q_j \\
    0 & \text{altrimenti}
  \end{cases}
\end{equation*}

In altri termini, poiché che l'algoritmo verifica l'esistenza di un cammino di lunghezza maggiore di
1 tra ogni coppia di stati $q_i, q_j \in Q'$, trattando l'automa come un grafo, il problema può essere ricondotto 
al calcolo della chiusura transitiva di quest'ultimo. 
Sono noti diversi algoritmi per lo svolgimento di tale compito \parencite{DFI08}. Un possibile approccio classico potrebbe
essere quello di utilizzare l'algoritmo di Floyd-Warshall, che richiede tempo $\bigo(n^3)$, tuttavia, in questo 
caso specifico, è possibile sfruttare una ricerca in ampiezza (BFS) partendo da ogni stato $q_i \in Q'$ per
ottenere gli stati raggiungibili da $q_i$ e popolare la corrispondente riga nella matrice $E$, ottenendo
così un tempo di esecuzione $\bigo(n^2 \cdot m)$.

Ricordando ancora una volta che grazie alla minimizzazione nell'automa $A'$ non sono presenti stati irraggiungibili,
è ora possibile distinguere in $Q'$ gli stati kernel da quelli preambolo, si costruisce a questo scopo
un vettore $K$ di dimensione $||Q'||$ tale che $k_i = 1$ se e solo se $q_i \in K(A')$, altrimenti $k_i = 0$.
Grazie al Lemma \ref{lem:kernel-state} la costruzione del vettore $K$ si riduce nel determinare se per ogni
stato $q_i \in Q'$, esista uno stato $q_j \in Q'$ tale che $e_{1,j} = e_{j,j} = e_{j,i} = 1$.

È banale dunque osservare come la costruzione del vettore $K$ sia eseguita in tempo $\bigo(n)$ essendo che 
per ogni stato $q_i \in Q'$ la verifica di appartenenza a $K(A')$ richiede un tempo costante $\bigo(1)$.

L'algoritmo procede con la determinazione delle classi di quasi-equivalenza, a questo scopo, viene creato un vettore
$R$ di dimensione $||Q'||$ che conterrà in posizione $i$ l'indice $j$ della classe di quasi-equivalenza 
$Q_j \in \partitioned{Q}{\sim}$ a cui lo stato $q_i$ appartiene. 

Inizialmente, $R$ viene inizializzato in modo tale che rappresenti la partizione di $Q'$ composta esclusivamente
da singoletti $Q' = \{ q_1 \} \cup \{ q_2 \} \cup \dots \cup \{ q_{||Q'||} \}$, ovvero, 
$\forall i \in \{ 1, \dots, ||Q'|| \}, r_i = i$. 
La costruzione avviene iterativamente, si cercano coppie di stati $q_i \in Q_i$ e $q_j \in Q_j$,
con $i \neq j$, tali che $\forall \sigma \in \Sigma$ si abbia
che $\delta'(q_i, \sigma)$ e $\delta'(q_j, \sigma)$ appartengano alla stessa classe di
quasi-equivalenza $Q_l \in \partitioned{Q'}{\sim}$.
Se tale coppia di stati viene trovata, seguendo quanto riportato nel Lemma \ref{lem:aeq-states},
significa che $q_i \sim q_j$ pertanto si uniscono le classi $Q_i$ e $Q_j$ in un'unica classe e si
aggiorna il vettore $R$ di conseguenza. Il processo termina quando non vengono trovate nuove coppie
di stati che soddisfino i requisiti, il che genera al più $||Q'|| - 1$ iterazioni.

Risulta immediato stabilire che il tempo richiesto per l'inizializzazione del vettore $R$ sia lineare rispetto
al numero di stati dell'automa e che pertanto il tempo necessario a tale operazione sia $\bigo(n)$.
Necessita invece un'analisi più approfondita il calcolo della complessità temporale relativa
alla costruzione di $R$: scandire le coppie di stati in $Q'$ richiede un tempo $\bigo(n^2)$, mentre la verifica
della quasi-equivalenza per ciascuna coppia richiede un tempo $\bigo(m)$, essendo inoltre il processo iterato
al più $||Q'|| - 1$ volte, la complessità temporale totale risulta essere $\bigo(n^3 \cdot m)$.

Infine, per ottenere l'automa $A''$ iperminimo, considerando l'insieme delle classi di quasi-equivalenza
rappresentato dal vettore $R$, si esaminano iterativamente tutti i $Q_i \in \partitioned{Q'}{\sim}$
collassando ove possibile gli stati seguendo quanto descritto nel punto 4 della strategia generale riportata
nella Sezione \ref{sec:hyperminimization-strategy}.

Il tempo complessivo richiesto dall'algoritmo per la costruzione dell'automa
iperminimo $A''$ risulta quindi essere $\bigo(n^3 \cdot m)$.

Supponendo, a titolo di esempio, di stare iperminimizzando l'automa $A'$ in Figura \ref{fig:minified-dfa},
la matrice $E$ costruita dall'algoritmo risulterebbe essere:
\begin{center}
  $E = \begin{bNiceMatrix}[last-col, first-row]
    \scriptstyle{A} & \scriptstyle{B} & \scriptstyle{C} & \scriptstyle{D} & \scriptstyle{E} & \scriptstyle{F} & \scriptstyle{G} \\
    0 & 1 & 1 & 1 & 1 & 1 & 1 & \scriptstyle{A} \\
    0 & 0 & 0 & 1 & 1 & 1 & 1 & \scriptstyle{B} \\
    0 & 0 & 0 & 1 & 1 & 1 & 1 & \scriptstyle{C} \\
    0 & 0 & 0 & 0 & 0 & 0 & 1 & \scriptstyle{D} \\
    0 & 0 & 0 & 0 & 1 & 1 & 1 & \scriptstyle{E} \\
    0 & 0 & 0 & 0 & 1 & 1 & 1 & \scriptstyle{F} \\
    0 & 0 & 0 & 0 & 0 & 0 & 1 & \scriptstyle{G} \\
  \end{bNiceMatrix}$
\end{center}

mentre i vettori $K$ dei kernel e $R$ delle classi di quasi-equivalenza risulterebbero essere:

\begin{center}
  $K = \begin{bNiceMatrix}[last-row]
    0 & 0 & 0 & 0 & 1 & 1 & 1 \\
    \scriptstyle{A} & \scriptstyle{B} & \scriptstyle{C} & \scriptstyle{D} & \scriptstyle{E} & \scriptstyle{F} & \scriptstyle{G}
  \end{bNiceMatrix}$, 
  \
  $R = \begin{bNiceMatrix}[last-row]
    A & F & C & D & E & F & D \\
    \scriptstyle{A} & \scriptstyle{B} & \scriptstyle{C} & \scriptstyle{D} & \scriptstyle{E} & \scriptstyle{F} & \scriptstyle{G}
  \end{bNiceMatrix}$
\end{center}

\subsection{Algoritmo di Badr}

L'algoritmo proposto da Andrew Badr \parencite{Badr} migliora la complessità temporale dell'algoritmo
di Badr, Geffert e Shipman cambiando la strategia utilizzata per identificare le classi di
quasi-equivalenza.

Equivalentemente all'algoritmo precedente, l'algoritmo di Badr come prima operazione minimizza l'automa
in ingresso $A$ ottenendo l'automa minimo $A' = (Q', \Sigma, \delta', q_I', \\F')$.

Il passo successivo prevede di identificare le classi di quasi-equivalenza. A questo scopo, si introduce
una nuova operazione tra automi a stati finiti deterministici e un importante risultato ad essa associato.

\begin{definition}
  Siano $A_1 = (Q_1, \Sigma, \delta_1, q_{I_1}, F_1)$ e $A_2 = (Q_2, \Sigma, \delta_2, q_{I_2}, F_2)$ due DFA,
  si definisce lo \emph{XOR cross product} tra $A_1$ e $A_2$, denotato con $A_1 \otimes A_2$, come l'automa 
  $A^\otimes = (Q^\otimes, \Sigma, \delta^\otimes, q_{I}^\otimes, F^\otimes)$ tale che:
  \begin{enumerate}
    \item $Q^\otimes = \{ (q_1, q_2) : q_1 \in Q_1 \wedge q_2 \in Q_2 \}$
    \item $\forall q_1 \in Q_1, \forall q_2 \in Q_2, \forall \sigma \in \Sigma : \delta^\otimes((q_1, q_2), \sigma) = (\delta_1(q_1, \sigma), \delta_2(q_2, \sigma))$
    \item $q_{I}^\otimes = (q_{I_1}, q_{I_2})$
    \item $F^\otimes = \{ (q_1, q_2) : (q_1 \in F_1) \otimes (q_2 \in F_2) \}$, con $\otimes$ operazione di XOR
  \end{enumerate}
\end{definition}

Un esempio di XOR cross product è quello tra l'automa in Figura \ref{fig:minified-dfa} e se stesso, il cui
risultato è riportato in Figura \ref{fig:dfa-xcp} e di cui, per una maggiore chiarezza, si riporta la tabella
di transizione in Tabella \ref{tab:dfa-xcp-transitions}.

\begin{definition}
  Sia $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico, si estende la nozione
  di linguaggio riconosciuto da $A$ ad un generico stato $q \in Q$, denotato con $L(q)$ e definito \emph{linguaggio
  indotto} da $q$, come l'insieme $L(q) = \{ w \in \Sigma^* : \delta(q, w) \in F \}$.
\end{definition}

\begin{theorem}\label{th:cross-prod-state-aeq}
  Siano $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico minimo e 
  $A^\otimes = (Q^\otimes, \Sigma, \delta^\otimes, q_{I}^\otimes, F^\otimes)$ l'automa risultante dallo 
  XOR cross product di $A$ con se stesso, allora: $\forall w \in \Sigma^*$ e $\forall (q_A, q_B) \in Q^\otimes$
  si ha $w \in L((q_A, q_B)) \Leftrightarrow \delta^\otimes((q_A, q_B), w) \in F^\otimes \Leftrightarrow 
  (\delta(q_A, w) \in F) \otimes (\delta(q_B, w) \in F)$.
  In altri termini, il linguaggio $L((q_A, q_B))$ di ogni stato nel contesto $A^\otimes$, è uguale al linguaggio
  $L(q_A) \Delta L(q_B)$ nel contesto $A$.
\end{theorem}
\begin{corollary}\label{cor:cross-prod-state-aeq-S}
  Siccome $A$ è minimo e dunque non esistono due stati $q_A, q_B \in Q$, con $q_A \neq q_B$, tali che inducano 
  il medesimo linguaggio, l'insieme degli stati $S = \{ (q, q) : q \in Q \}$ è esattamente l'insieme degli
  stati in $A^\otimes$ che inducono $L_\emptyset$.
\end{corollary}
\begin{corollary}\label{cor:cross-prod-state-aeq-states}
  Il linguaggio indotto da uno stato $(q_A, q_B) \in Q^\otimes$ è finito se e solo se $q_A \sim q_B$, pertanto, 
  l'insieme degli stati in $A^\otimes$ che inducono un linguaggio finito è la relazione di quasi-equivalenza
  sugli stati in $A$.
\end{corollary}

L'idea alla base dell'algoritmo di Badr è quella di utilizzare l'automa $A^\otimes$ prodotto dallo 
XOR cross product tra l'automa minimo $A'$ e se stesso, la cui costruzione richiede tempo $\bigo(n^2)$,
per computare $\partitioned{Q'}{\sim}$.
In particolare, l'algoritmo utilizza il sottoinsieme $R \subset Q^\otimes$ di tutti gli stati
che inducono un linguaggio finito in $A^\otimes$ per calcolare le classi di quasi-equivalenza su $Q'$.

A questo scopo si calcola l'insieme degli stati che inducono il linguaggio vuoto $S$ in $A^\otimes$ ed il suo 
insieme complementare $S^c$. Si osservi come, dato un automa a stati finiti deterministico generico 
$M = (Q_M, \Sigma_M, \delta_M, q_{I_M}, F_M)$, l'insieme degli stati che inducono un linguaggio vuoto in $M$
è per definizione $S_M = \{q \in Q_M \ t.c. \ \forall w \in \Sigma^*_M, \ \delta_M(q, w) \notin F_M\}$ che in
$A^\otimes$, per il Corollario \ref{cor:cross-prod-state-aeq-S}, corrisponde all'insieme $S = \{ (q, q) : q \in Q' \}$. 
È banale dunque osservare come la costruzione di $S$ e $S^c$ richiede un tempo $\bigo(n)$.

\begin{figure}
  \centering
  \includegraphics[width=0.5\linewidth]{images/dfa_xcp.png}
  \caption{\label{fig:dfa-xcp}L'automa in Figura \ref{fig:minified-dfa} in XOR cross product con se stesso.}
\end{figure}

\begin{table}[!htb]
  \centering
  \begin{tabular}[t]{r|c|c}
    \toprule
                          & $a$       & $b$       \\
    \midrule
    $\rightarrow (A, A)$  & $(B, B)$  & $(C, C)$  \\
    $(A, B)$              & $(B, E)$  & $(C, D)$  \\
    $(A, C)$              & $(B, D)$  & $(C, F)$  \\
    $(A, D)$              & $(B, G)$  & $(C, G)$  \\
    $(A, E)$              & $(B, F)$  & $(C, G)$  \\
    $(A, F)$              & $(B, E)$  & $(C, G)$  \\
    $(A, G)$              & $(B, G)$  & $(C, G)$  \\
    $(B, A)$              & $(E, B)$  & $(D, C)$  \\
    $(B, B)$              & $(E, E)$  & $(D, D)$  \\
    $(B, C)$              & $(E, D)$  & $(D, F)$  \\
    $(B, D)$              & $(E, G)$  & $(D, G)$  \\
    $(B, E)$              & $(E, F)$  & $(D, G)$  \\
    $(B, F)$              & $(E, E)$  & $(D, G)$  \\
    $(B, G)$              & $(E, G)$  & $(D, G)$  \\
    $(D, B)$              & $(G, E)$  & $(G, D)$  \\
    $(D, C)$              & $(G, D)$  & $(G, F)$  \\
    $(D, D)$              & $(G, G)$  & $(G, G)$  \\
    $(C, A)$              & $(D, B)$  & $(F, C)$  \\
    $(C, B)$              & $(D, E)$  & $(F, D)$  \\
    $(C, C)$              & $(D, D)$  & $(F, F)$  \\
    $(C, D)$              & $(D, G)$  & $(F, G)$  \\
    $(C, E)$              & $(D, F)$  & $(F, G)$  \\
    $(C, F)$              & $(D, E)$  & $(F, G)$  \\
    $(C, G)$              & $(D, G)$  & $(F, G)$  \\
    $(D, A)$              & $(G, B)$  & $(G, C)$  \\
    \bottomrule
  \end{tabular}
  \quad
  \begin{tabular}[t]{r|c|c}
    \toprule
              & $a$       & $b$       \\
    \midrule
    $(D, E)$  & $(G, F)$  & $(G, G)$  \\
    $(D, F)$  & $(G, E)$  & $(G, G)$  \\
    $(D, G)$  & $(G, G)$  & $(G, G)$  \\
    $(E, A)$  & $(F, B)$  & $(G, C)$  \\
    $(E, B)$  & $(F, E)$  & $(G, D)$  \\
    $(E, C)$  & $(F, D)$  & $(G, F)$  \\
    $(E, D)$  & $(F, G)$  & $(G, G)$  \\
    $*(E, E)$ & $(F, F)$  & $(G, G)$  \\
    $(E, F)$  & $(F, E)$  & $(G, G)$  \\
    $*(E, G)$ & $(F, G)$  & $(G, G)$  \\
    $(F, A)$  & $(E, B)$  & $(G, C)$  \\
    $(F, B)$  & $(E, E)$  & $(G, D)$  \\
    $(F, C)$  & $(E, D)$  & $(G, F)$  \\
    $(F, D)$  & $(E, G)$  & $(G, G)$  \\
    $(F, E)$  & $(E, F)$  & $(G, G)$  \\
    $(F, F)$  & $(E, E)$  & $(G, G)$  \\
    $(F, G)$  & $(E, G)$  & $(G, G)$  \\
    $(G, A)$  & $(G, B)$  & $(G, C)$  \\
    $(G, B)$  & $(G, E)$  & $(G, D)$  \\
    $(G, C)$  & $(G, D)$  & $(G, F)$  \\
    $(G, D)$  & $(G, G)$  & $(G, G)$  \\
    $*(G, E)$ & $(G, F)$  & $(G, G)$  \\
    $(G, F)$  & $(G, E)$  & $(G, G)$  \\
    $*(G, G)$ & $(G, G)$  & $(G, G)$  \\
    \bottomrule
  \end{tabular}
  \caption{\label{tab:dfa-xcp-transitions}Tabella di transizione dell'automa in Figura \ref{fig:dfa-xcp}.}
\end{table}

Una volta calcolati $S$ e $S^c$, l'algoritmo procede istanziando per ogni stato $q \in Q^\otimes$ due insiemi
$T^\rightarrow_q = \emptyset$ e $T^\leftarrow_q = \emptyset$ che conterranno rispettivamente gli stati raggiungibili
da $q$ e gli stati che possono raggiungere $q$. La costruzione di $T^\rightarrow_q$ e $T^\leftarrow_q$ avviene
iterativamente: per ogni stato $q \in S^c$ e per ogni $\sigma \in \Sigma$, sia $q' = \delta^\otimes(q, \sigma)$,
allora $T^\rightarrow_q = T^\rightarrow_q \cup \{ (q', \sigma) \}$ e 
$T^\leftarrow_{q'} = T^\leftarrow_{q'} \cup \{ (q, \sigma) \}$.

In seguito, viene costruito l'insieme $R$, inizializzato come $R = \emptyset$, iterativamente: fino a quando
$S \neq \emptyset$, si estrae uno stato $q \in S$ e lo si aggiunge ad $R$, si rimuove $q$ da $S$ e 
$\forall (q', \sigma) \in T_q^\leftarrow$ si rimuove $(q, \sigma)$ da $T_{q'}^\rightarrow$ e se, in seguito
a tale rimozione, $T_{q'}^\rightarrow = \emptyset$, si aggiunge $q'$ a $S$.

\begin{theorem}\label{th:rfs-correctness}
  L'algoritmo appena descritto aggiunge uno stato all'insieme $R$ se e solo se induce un linguaggio finito in $A^\otimes$.
\end{theorem}

Al termine di questo processo, grazie al risultato esposto nel Teorema \ref{th:rfs-correctness}, per la cui dimostrazione
il lettore è rimandato a \parencite{Badr}, l'insieme $R$ conterrà come da obiettivo tutti gli stati che inducono
un linguaggio finito in $A^\otimes$ e sarà possibile costruire $\partitioned{Q'}{\sim}$.

Essendo il numero di transizioni lineare rispetto al numero di stati, il tempo necessario alla costruzione 
di $T^\rightarrow_q$ e $T^\leftarrow_q$ per tutti gli stati corrisponde complessivamente a $\bigo(||Q^\otimes||)$.
Inoltre, l'aggiunta di ogni stato ad $R$ richiede un tempo costante $\bigo(1)$ più un tempo trascurabile per ciascuno
stato da cui si raggiunge quello corrente, pertanto la costruzione di $R$ richiede anch'essa un tempo
lineare $\bigo(||Q^\otimes||)$. Ricordando che $A^\otimes$ è lo XOR cross product di $A'$ con se stesso, la complessità
temporale di questo passaggio è $\bigo(n^2)$.

La costruzione di $\partitioned{Q'}{\sim}$ avviene ora semplicemente, utilizzando una struttura dati QuickFind $U$ con 
bilanciamento \parencite{DFI08}. La struttura viene inizializzata per rappresentare la partizione
di $Q'$ composta esclusivamente da singoletti, quindi, per ogni stato $(q_A, q_B) \in R$, siano $Q_i$ e $Q_j$
rispettivamente i risultati delle operazioni di $find(q_A)$ e $find(q_B)$ in $U$, se $Q_i \neq Q_j$, 
allora si uniscono gli insiemi $Q_i$ e $Q_j$ tramite l'operazione $union(Q_i, Q_j)$ in $U$. Per il 
Corollario \ref{cor:cross-prod-state-aeq-states}, al termine dell'operazione, $U$ rappresenterà $\partitioned{Q'}{\sim}$.

Dato l'utilizzo di una struttura dati QuickFind con bilanciamento, il costo della singola operazione di $find$
è costante, mentre il costo della singola operazione di $union$ è lineare, pertanto
poiché per la costruzione di $\partitioned{Q'}{\sim}$ vengono eseguite al più $n - 1$ operazioni di $union$ e si
itera su tutti gli stati in $R$, la complessità temporale di questo passaggio è $\bigo(n^2)$.

Il calcolo degli insieme $K(A')$ e $P(A')$ avviene in tempo $\bigo(n^2)$. L'idea è simile a quella dell'algoritmo di 
Badr, Geffert e Shipman, ma in questo caso ne viene cambiata la messa in pratica. Si inizializza l'insieme 
$K = \emptyset$ che conterrà gli stati kernel e si procede iterativamente: per ogni stato $q \in Q'$ si ottiene
l'insieme degli stati raggiungibili da $q$ in $A'$ con un cammino di lunghezza maggiore di 1, se tale insieme
contiene $q$ allora si aggiunge $q$ a $K$. Al termine del processo, $K$ conterrà tutti gli stati kernel e l'insieme
$P = P(A')$ sarà dato da $Q' \setminus K$.

Infine, l'automa iperminimo $A''$ viene costruito: per ogni classe di quasi-equivalenza $Q_i \in U$,
si ottiene l'insieme $P_{Q_i}$ degli stati preambolo in $Q_i$ e l'insieme $K_{Q_i}$ degli stati kernel in $Q_i$
tramite intersezione di $Q_i$ rispettivamente con $P$ e $K$. Si procede dunque al collasso di tutti gli stati
in $P_{Q_i}$ in uno stato $q_K \in K_{Q_i}$, se $K_{Q_i}$ è non vuoto, o al collasso in 
$q_P \in P_{Q_i}$ degli stati in $P_{Q_i} \setminus \{ q_P \}$ altrimenti.

Utilizzando ancora una volta come esempio l'automa $A'$ in Figura \ref{fig:minified-dfa}, l'automa $A^\otimes$
risultante dallo XOR cross product tra $A'$ e se stesso è stato mostrato essere quello descritto in Tabella 
\ref{tab:dfa-xcp-transitions}. L'insieme $S$ degli stati che inducono un linguaggio finito in $A^\otimes$ 
ne segue essere $S = \{ (A, A), (B, B), (C, C), (D, D), (E, E), (F, F), (G, G) \}$, da cui l'insieme $R$ 
degli stati che inducono un linguaggio finito in $A'$ costruito dall'algoritmo è 
$R = S \cup \{ (B, F), (F, B), (D, G), (G, D) \}$. L'insieme delle classi di quasi-equivalenza
rappresentato da $U$ risulta correttamente essere $\{ \{ A \}, \{ B, F \}, \{ C \}, \{ D, G \}, \{ E \} \}$.

\subsection{Algoritmo di Holzer e Maletti}
\label{sec:hm-algorithm}

L'ultimo algoritmo presentato è quello proposto da Holzer e Maletti \parencite{HM10}, questo migliora i risultati
ottenuti in precedenza infatti, introducendo una nuova stategia per l'identificazione degli stati
kernel e per la costruzione delle classi di equivalenza, riduce la complessità temporale a $\bigo(n\log n)$.

Siano $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico e $q_A, q_B \in Q$ due stati,
si definisce formalmente una funzione \emph{merge} utilizzata in seguito dall'algoritmo per il collasso
degli stati come $merge(\delta, q_I, q_A, q_B) = (\delta', q_I')$ tale che $\forall q' \in Q$ e
$\forall \sigma \in \Sigma$:
\begin{equation*}
  \delta'(q', \sigma) =
  \begin{cases}
    q_B                 & \text{se } \delta(q', \sigma) = q_A \\
    \delta(q', \sigma)  & \text{altrimenti}
  \end{cases}
  \text{ e } 
  q_I' =
  \begin{cases}
    q_B & \text{se } q_I = q_A \\
    q_I & \text{altrimenti}
  \end{cases}
\end{equation*}

L'algoritmo inizia seguendo quella che è la linea generale degli algoritmi precedenti: minimizza 
l'automa in ingresso ottenendo l'automa minimo $A' = (Q', \Sigma, \delta', q_I', F')$.

\begin{definition}
  Sia $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico, uno stato $q \in Q$ è detto
  \emph{stato centrale} se $\exists w \in \Sigma^* \setminus \{ \varepsilon \}$ tale che $\delta(q, w) = q$.
\end{definition}

Il passo successivo prevede di identificare l'insieme $K(A')$ degli stati kernel in $A'$. L'idea alla base
della strategia utilizzata dall'algoritmo è quella di identificare l'insieme $C$ degli stati centrali in $A'$ 
attraverso una versione dell'algoritmo di Tarjan \parencite{DFI08} per l'identificazione delle componenti fortemente
connesse semplificata in quanto, essendo $A'$ minimo, tutti gli stati in $Q'$ sono raggiungibili da $q_I'$. 
Questo avviene semplicemente in quanto, per definizione, gli stati centrali sono parte di una
componente fortemente connessa di almeno due stati o hanno un ciclo su loro stessi.
Una volta costruito l'insieme $C$ una Depth-First Search \parencite{DFI08} viene utilizzata per identificare tutti
gli stati raggiungibili da uno stato centrale, questi stati sono gli stati kernel per il Lemma \ref{lem:kernel-state}.

L'algoritmo passa ora ad occuparsi della costruzione delle classi di quasi-equivalenza. Per ottenere una migliore
complessità temporale rispetto agli algoritmi precedenti, la strategia utilizzata prevede di evitare i confronti
tra coppie, che migliora la complessità di un fattore $\bigo(n)$, e di collassare gli stati con una metodologia 
specifica che riduce un fattore $\bigo(n)$ a $\bigo(\log n)$. 

\begin{definition}
  Sia $A = (Q, \Sigma, \delta, q_I, F)$ un automa a stati finiti deterministico. Si definisce
  \emph{vettore dei successori} di $q \in Q$ il vettore $V(q) = [\delta(q, \sigma) \ | \ \sigma \in \Sigma]$.
\end{definition}

Nel dettaglio, l'algoritmo mantiene un insieme $I$ degli stati che devono essere processati e 
un insieme $P$ degli stati che sono ancora utili, entrambi inizializzati uguali a $Q'$,
una tabella hash $H$ inizialmente vuota che mappa vettori dei successori a stati,
una partizione $R$ di $Q'$ che ne rappresenta in partenza la partizione in singoletti, 
una funzione $\delta_\sim = \delta'$ e uno stato $q_{I_\sim} = q_I'$. 
A questo punto, fin tanto che $I \neq \emptyset$, iterativamente viene rimosso uno stato $q_A$ da $I$ e ne viene
calcolato $V(q_A)$, se a $V(q_A)$ non è associato alcun valore in $H$ allora si assegna a $V(q_A)$ lo stato $q_A$ in
$H$ e si prosegue con l'iterazione successiva, altrimenti, se è già associato uno stato $q_B$ a $V(q_A)$ in $H$, 
si determina lo stato tra $q_A$ e $q_B$ la cui cardinalità della parte in $R$ della quale è elemento è minore.
Supponendo che tale stato sia $q_A$, questo viene viene rimosso da $P$ trattandosi di uno stato inutile
in quanto collassato in $q_B$ nei prossimi passaggi, 
vengono aggiunti a $I$ tutti gli stati $q \in P$ per i quali $\exists \sigma \in \Sigma$ tale che
$\delta_\sim(q, \sigma) = q_A$, si effettua il $merge(\delta_\sim, q_{I_\sim}, q_A, q_B)$ aggiornando
con i valori restituiti la funzione di transizione $\delta_\sim$ e lo stato $q_{I_\sim}$ e 
si modifica la partizione $R$ unendo le parti in $R$ a cui appartengono $q_A$ e $q_B$. In ultima istanza, 
sempre in tale caso, si aggiorna il valore associato a $V(q_A)$ in $H$ con $q_B$.

\begin{theorem}\label{th:aeq-correctness}
  L'algoritmo appena descritto costruisce correttamente $\partitioned{Q'}{\sim}$.
\end{theorem}

\begin{theorem}
  \label{th:hm-complexity}
  Gli algoritmi descritti per l'identificazione degli stati kernel e per la costruzione di
  $\partitioned{Q'}{\sim}$ possono essere implementati in modo tale che la loro computazione richieda rispettivamente
  tempo $\bigo(m)$ e $\bigo(m \log n)$.
\end{theorem}

Le dimostrazioni dei Teoremi \ref{th:aeq-correctness} e \ref{th:hm-complexity} risultano essere particolarmente
lunghe e complesse, nonchè il fulcro del lavoro di Holzer e Maletti, pertanto sono volontariamente omesse 
nel presente elaborato ed il lettore è rimandato a \parencite{HM10}.

Banalmente, l'ultimo passaggio dell'algoritmo consiste nel costruire l'automa iperminimo $A''$ a partire dai 
risultati ottenuti dai passaggi precedenti. Iterativamente, per ogni classe di equivalenza $Q_i \in R$, 
se l'intersezione tra $Q_i$ e $K(A')$ è non vuota, si sceglie arbitrariamente uno stato $q$ al suo interno,
altrimenti si sceglie un qualsiasi stato $q$ in $Q_i$, e $\forall q' \in Q_i \setminus K(A')$ si 
collassa $q'$ in $q$ e si aggiornano i valori di $\delta'$ e $q_I'$ tramite $merge(\delta', q_{I}', q, q')$
ottenendo l'automa iperminimo $A''$.

Ipotizzando di eseguire l'algoritmo sull'automa $A'$ in Figura \ref{fig:minified-dfa}, l'insieme $C$ degli stati
centrali risulta essere $C = \{ F, G, E \}$ dal quale viene correttamente identificato
l'insieme $K(A')$ degli stati kernel in $A'$ attraverso la visita in profondità. Ulteriormente, l'insieme $R$ delle
classi di quasi-equivalenza, costruito sulla tabella $H$ il cui contenuto al termine dell'algoritmo è riportato
in Tabella \ref{tab:hm-hash-table}, risulta correttamente essere $\partitioned{Q'}{\sim}$ come previsto dal Teorema
\ref{th:aeq-correctness}.

\begin{table}[!htb]
  \centering
  \begin{tabular}{r|c}
    \toprule
    Chiave & Valore  \\
    \midrule
    $[B, C]$  & $A$  \\
    $[D, F]$  & $C$  \\
    $[G, G]$  & $D$  \\
    $[E, G]$  & $F$  \\
    $[E, D]$  & $B$  \\
    $[F, D]$  & $E$  \\
    $[B, D]$  & $E$  \\
    $[D, D]$  & $D$  \\
    $[D, B]$  & $C$  \\
    \bottomrule
  \end{tabular}
  \caption{\label{tab:hm-hash-table}Tabella hash $H$ al termine dell'esecuzione dell'algoritmo\\sull'automa in Figura \ref{fig:minified-dfa}.}
\end{table}

% CHAPTER 3

\chapter{Implementazione}
\label{cap3}

\section{Introduzione}

In questo capitolo vengono presentate delle possibili implementazioni degli algoritmi 
di iperminimizzazione descritti nel Capitolo \ref{cap2}. Ciascun algoritmo è suddiviso in 
funzioni che implementano i singoli passaggi presentati nella descrizione teorica, in modo da
rendere più chiara la struttura dello pseudocodice e facilitarne la comprensione.

\section{Algoritmo di Badr, Geffert e Shipman}

Si presenta in primo luogo l'implementazione della funzione principale dell'algoritmo di Badr, Geffert e
Shipman il cui pseudocodice è riportato nell'Algoritmo \ref{algo:bgs-algorithm}.

Successivamente, vengono mostrate le implementazioni delle funzioni ausiliarie 
utilizzate dall'algoritmo principale.

\begin{algo}{Algoritmo di Badr, Geffert e Shipman.}
  {Un automa a stati finiti deterministico $A = (Q, \Sigma, \delta, q_I, F)$}
  {Uno dei possibili automi iperminimi quasi-equivalenti ad $A$}
  \label{algo:bgs-algorithm}

  $A' \gets minimize(A)$\;

  $K \gets kernelStates(A')$ \Comment*[r]{Algoritmo \ref{algo:bgs-kernel-states}}

  $R \gets almostEquivalenceClasses(A')$ \Comment*[r]{Algoritmo \ref{algo:bgs-almost-equivalence-classes}}

  $mergeStates(A', K, R)$ \Comment*[r]{Algoritmo \ref{bgs:bgs-merge-states}}

  \Return{$A'$}
\end{algo}

Nel dettaglio:
\begin{enumerate}[label=--]
  \item l'Algoritmo \ref{algo:bgs-kernel-states} implementa la funzione \emph{kernelStates} che, dato un
  automa minimo in ingresso, restituisce l'insieme degli stati kernel nell'automa;
  \item l'Algoritmo \ref{algo:bgs-almost-equivalence-classes} implementa la funzione \emph{almostEquivalenceClasses}
  che, dato un automa minimo in ingresso, restituisce un vettore che associa ad ogni stato dell'automa l'indice della
  classe di quasi-equivalenza a cui appartiene;
  \item l'Algoritmo \ref{bgs:bgs-merge-states} implementa la funzione \emph{mergeStates} che, dato un automa
  minimo in ingresso, costruisce uno dei possibili automi iperminimi quasi-equivalenti ad esso.
\end{enumerate}

\begin{algo}{Algoritmo per l'ottenimento dell'insieme degli stati kernel.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$}
  {L'insieme degli stati kernel $K(A)$}
  \label{algo:bgs-kernel-states}

  $E \gets \text{matrice di zeri di dimensione } ||Q|| \times ||Q||$\;

  \For{$i \gets 1$ \KwTo $||Q||$}{
    $V_i \gets breadthFirstSearch(A, q_i)$\;
    \For{$j \gets 1$ \KwTo $||Q||$}{
      \lIf{$q_j \in V_i$}{$E[i][j] \gets 1$}
    }
  }

  $K \gets \emptyset$\;
  \For{$i \gets 1$ \KwTo $||Q||$}{
    \For{$j \gets 1$ \KwTo $||Q||$}{
      \If{$E[1][j] = 1$ and $E[j][j] = 1$ and $E[j][i] = 1$}{
        $K \gets K \cup \{ q_i \}$\;
        \textbf{break}\;
      }
    }
  }

  \Return{$K$}\;
\end{algo}

Si ritiene importante puntualizzare come, la funzione \emph{breadthFirstSearch} utilizzata nell'Algoritmo
\ref{algo:bgs-kernel-states} per ottenere l'insieme $V_i$ degli stati raggiungibili da uno stato $q_i$ in $A$,
non sia la versione classica della Breadth-First Search, ma una versione modificata che non aggiunge nella
prima iterazione lo stato $q_i$ di partenza all'insieme degli stati visitati. Ne segue che $q_i$ si troverà
nell'insieme $V_i$ se e solo se raggiungibile da uno stato $q_j$, con $q_j \neq q_i$,
tale che $q_j$ sia raggiungibile da $q_i$ o se $q_i$ ha un ciclo su se stesso.

\begin{algo}{Algoritmo per il calcolo delle classi di quasi-equivalenza.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$}
  {Un vettore che associa ad ogni stato $q_i \in Q$ l'indice $j$ della classe di quasi-equivalenza $Q_j$ a cui appartiene}
  \label{algo:bgs-almost-equivalence-classes}

  $R \gets \text{vettore di dimensione } ||Q||$\;
  \For{$i \gets 1$ \KwTo $||Q||$}{
    $R[i] \gets i$\;
  }
  \DoWhile{$ae\_found$}{
    $ae\_found \gets false$\;
    \ForEach{$q_i \in Q$}{
      \ForEach{$q_j \in Q \text{ tale che } j > i$}{
        \If{$R[i] \neq R[j]$}{
          $ae \gets true$\;
          \ForEach{$\sigma \in \Sigma$}{
            \If{$R[\delta(q_i, \sigma)] \neq R[\delta(q_j, \sigma)]$}{
              $ae \gets false$\;
              \textbf{break}\;
            }
          }
          \If{$ae$}{
            \ForEach{$q \in Q$}{
              \lIf{$R[q] = R[j]$}{$R[q] \gets R[i]$}
            }
            $ae\_found \gets true$\;
          }
        }
      }
    }
  }

  \Return{$R$}\;
\end{algo}

\begin{algo}{Algoritmo per la costruzione dell'automa iperminimo.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$, l'insieme
  degli stati kernel $K(A)$ e il vettore delle classi di quasi-equivalenza $R$}
  {Al termine dell'esecuzione dell'algoritmo, $A$ sarà iperminimo}
  \label{bgs:bgs-merge-states}

  \For{$i \gets 1$ \KwTo $||Q'||$}{
    $K_{Q_i}$, $P_{Q_i} \gets \emptyset, \emptyset$\;
    \For{$j \gets 1$ \KwTo $||Q'||$}{
      \If{$R[j] = i$}{
        \If{$q_j \in K$}{
          $K_{Q_i} \gets K_{Q_i} \cup \{ q_j \}$\;
        }
        \Else{
          $P_{Q_i} \gets P_{Q_i} \cup \{ q_j \}$\;
        }
      }
    }

    \If{$P_{Q_i} \cup K_{Q_i} \neq \emptyset$}{
      $q \gets \text{un elemento qualunque di } P_{Q_i} \cup K_{Q_i}$\;
      \If{$P_{Q_i} \neq \emptyset$ and $K_{Q_i} \neq \emptyset$ and $q \notin K_{Q_i}$}{
        $q \gets \text{un elemento qualunque di } K_{Q_i}$\;
      }

      \ForEach{$q' \in P_{Q_i} \setminus \{ q \}$}{
        collassa lo stato $q'$ in $q$\;
      }
    }
  }
\end{algo}

\section{Algoritmo di Badr}

Seguendo la medesima linea dell'algoritmo precedente, si presenta l'implementazione dell'algoritmo di Badr
iniziando dalla funzione principale e procedendo con le funzioni ausiliarie.

\begin{algo}{Algoritmo di Badr.}
  {Un automa a stati finiti deterministico $A = (Q, \Sigma, \delta, q_I, F)$}
  {Uno dei possibili automi iperminimi quasi-equivalenti ad $A$}
  \label{algo:badr}

  $A' \gets minimize(A)$\;

  $U \gets almostEquivalenceClasses(A')$ \Comment*[r]{Algoritmo \ref{algo:badr-almost-equivalence-classes}}
  
  $P, K \gets preambleAndKernelStates(A')$ \Comment*[r]{Algoritmo \ref{algo:badr-kernel-states}}

  $mergeStates(A', U, P, K)$ \Comment*[r]{Algoritmo \ref{algo:badr-merge-states}}
  
  \Return{$A'$}
\end{algo}

In questo caso, le funzioni ausiliarie sono implementate come segue:
\begin{enumerate}[label=--]
  \item l'Algoritmo \ref{algo:badr-almost-equivalence-classes} implementa la funzione \emph{almostEquivalenceClasses}
  che, dato un automa minimo in ingresso, restituisce la partizione dell'insieme degli stati in classi di quasi-equivalenza;
  \item l'Algoritmo \ref{algo:badr-kernel-states} implementa la funzione \emph{preambleAndKernelStates} che, dato un
  automa minimo in ingresso, restituisce l'insieme degli stati preambolo e l'insieme degli stati kernel nell'automa;
  \item l'Algoritmo \ref{algo:badr-merge-states} implementa la funzione \emph{mergeStates} che, dato in ingresso
  un automa minimo $A$, la partizione dei suoi stati in classi di quasi-equivalenza ed i suoi stati kernel e preambolo,
  costruisce uno dei possibili automi iperminimi quasi-equivalenti all'automa in ingresso.
\end{enumerate}

\begin{algo}{Algoritmo per l'ottenimento degli stati kernel e preambolo.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$}
  {Gli insiemi $P(A)$ e $K(A)$}
  \label{algo:badr-kernel-states}

  $K \gets \emptyset$\;

  \ForEach{$q \in Q$}{
    $V \gets breadthFirstSearch(A, q)$\;
    \lIf{$q \in V$}{$K \gets K \cup V$}
  }

  \Return{$(Q \setminus K, K)$}
\end{algo}

\begin{algo}{Algoritmo per la computazione delle classi di quasi-equivalenza.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$}
  {L'insieme quoziente $\partitioned{Q}{\sim}$}
  \label{algo:badr-almost-equivalence-classes}

  $A^\otimes \gets A \otimes A$\;

  $S \gets \{ (q, q) : q \in Q \}$\;

  $R \gets finiteLanguageStates(A^\otimes, S)$ \Comment*[r]{Algoritmo \ref{algo:badr-right-finite-states}}
  
  $U \gets \text{struttura } QuickFind \text{ vuota}$\;
  \lForEach{$q \in Q$}{$U.makeset(q)$}
  \ForEach{$(q_A, q_B) \in R$}{
    $Q_i \gets U.find(q_A)$\;
    $Q_j \gets U.find(q_B)$\;
    \lIf{$Q_i \neq Q_j$}{$U.union(Q_i, Q_j)$}
  }

  \Return{$U$}\;
\end{algo}

Poiché l'implementazione dell'Algoritmo \ref{algo:badr-almost-equivalence-classes} per la costruzione delle classi
di quasi-equivalenza risulta essere particolarmente lunga, si utilizza un'ulteriore funzione ausiliaria
\emph{finiteLanguageStates} la cui implementazione è definita nell'Algoritmo \ref{algo:badr-right-finite-states}.

\begin{algo}{Algoritmo per la costruzione dell'automa iperminimo.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$, l'insieme
  quoziente $\partitioned{Q}{\sim}$ e gli insiemi $P(A)$ e $K(A)$}
  {Al termine dell'esecuzione dell'algoritmo, $A$ sarà iperminimo}
  \label{algo:badr-merge-states}

  \ForEach{$Q_i \in \partitioned{Q}{\sim}$}{
    $P_{Q_i} \gets Q_i \cap P(A)$\;
    $K_{Q_i} \gets Q_i \cap K(A)$\;

    
    \lIf{$K_{Q_i} \neq \emptyset$}{$q \gets \text{un elemento qualunque di } K_{Q_i}$}
    \lElse{$q \gets \text{un elemento qualunque di } P_{Q_i}$}
    
    \ForEach{$q' \in P_{Q_i} \setminus \{ q \}$}{collassa lo stato $q'$ in $q$}
  }
\end{algo}

Inoltre, si puntualizza nuovamente come, essendo l'idea dell'identificazione degli stati kernel basata
sulle medesime osservazioni fatte nell'algoritmo di Badr, Geffert e Shipman e dunque l'implementazione
molto simile, la funzione \emph{breadthFirstSearch} utilizzata nell'Algoritmo \ref{algo:badr-kernel-states}
contiene la stessa modifica descritta in precedenza.

\begin{algo}{Algoritmo per il calcolo degli stati che inducono un linguaggio finito.}
  {Un automa a stati finiti deterministico $A = (Q, \Sigma, \delta, q_I, F)$ e l'insieme $S$ degli stati che
  inducono un linguaggio vuoto in $A$}
  {L'insieme degli stati in $A$ che inducono un linguaggio finito}
  \label{algo:badr-right-finite-states}
  
  $S^c \gets Q \setminus S$\;

  \ForEach{$q \in Q$}{
    $T^\rightarrow_q \gets \emptyset$\;
    $T^\leftarrow_q \gets \emptyset$\;
  }

  \ForEach{$q \in S^c$}{
    \ForEach{$\sigma \in \Sigma$}{
      $q' \gets \delta(q, \sigma)$\;
      $T^\rightarrow_q \gets T^\rightarrow_q \cup \{(q', \sigma)\} $\;
      $T^\leftarrow_{q'} \gets T^\leftarrow_{q'} \cup \{(q, \sigma)\} $\;
    }
  }

  $R \gets \emptyset$\;
  \While{$S \neq \emptyset$}{
    $q \gets \text{un elemento qualunque di } S$\;
    $S \gets S \setminus \{q\}$\;
    $R \gets R \cup \{q\}$\;
    \ForEach{$(q', \sigma) \in T^\leftarrow_q$}{
      $T^\rightarrow_{q'} \gets T^\rightarrow_{q'} \setminus \{(q, \sigma)\}$\;
      \If{$T^\rightarrow_{q'} = \emptyset$}{
        $S \gets S \cup \{q'\}$\;
      }
    }
  }

  \Return{$R$}\;
\end{algo}

\section{Algoritmo di Holzer e Maletti}

Nuovamente, si procede con la presentazione dell'implementazione dell'algoritmo di Holzer e Maletti
partendo dalla funzione principale e proseguendo con le funzioni ausiliarie.

\begin{algo}{Algoritmo di Holzer e Maletti.}
  {Un automa a stati finiti deterministico $A = (Q, \Sigma, \delta, q_I, F)$}
  {Uno dei possibili automi iperminimi quasi-equivalenti ad $A$}
  \label{algo:hm-algorithm}
  
  $A' \gets minimize(A)$\;
  
  $K \gets kernelStates(A')$ \Comment*[r]{Algoritmo \ref{algo:hm-kernel-states}}

  $R \gets almostEquivalenceClasses(A')$ \Comment*[r]{Algoritmo \ref{algo:hm-almost-equivalence-classes}}

  $mergeStates(A', R, K)$ \Comment*[r]{Algoritmo \ref{algo:hm-hmdfa-build}}

  \Return{$A'$}\;
\end{algo}

Gli algoritmi che implementano le funzioni ausiliarie utilizzate dalla funzione principale sono organizzati come segue:
\begin{enumerate}[label=--]
  \item l'Algoritmo \ref{algo:hm-kernel-states} implementa la funzione \emph{kernelStates} che, dato in ingresso
  un automa minimo, ne identifica e restituisce l'insieme degli stati kernel;
  \item l'Algoritmo \ref{algo:hm-almost-equivalence-classes} implementa la funzione \emph{almostEquivalenceClasses}
  che, dato in ingresso un automa minimo, ne computa e restituisce la partizione degli stati in classi di quasi-equivalenza;
  \item l'Algoritmo \ref{algo:hm-hmdfa-build} implementa la funzione \emph{mergeStates} che, dato in ingresso un
  automa minimo, la partizione dei suoi stati in classi di quasi-equivalenza e l'insieme degli stati
  kernel, costruisce uno dei possibili automi iperminimi quasi-equivalenti all'automa in ingresso.
\end{enumerate}

\begin{algo}{Algoritmo per l'identificazione degli stati kernel.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$}
  {L'insieme degli stati kernel $K(A)$}
  \label{algo:hm-kernel-states}

  $index, low \gets \text{tabelle hash vuote che associano } q \in Q \text{ a } n \in \mathbb{N}$\;
  $i \gets 0$\;
  $S \gets \text{stack vuoto}$\;
  $K \gets \emptyset$\;
  $tarjan(A, q_I, index, low, i, S, K)$ \Comment*[r]{Algoritmo \ref{algo:hm-tarjan}}
  \Return{$K$}\;
\end{algo}

Si puntualizza come, nelle implementazioni dei diversi algoritmi che costituiscono le funzioni ausiliarie,
la funzione \emph{merge} corrisponda alla specifica strategia di collasso degli stati
ideata da Holzer e Maletti di cui una sua possibile implementazione è data nell'Algoritmo \ref{algo:hm-merge-states}.

\begin{algo}{Algoritmo per il collasso degli stati.}
  {Una funzione di transizione $\delta$, lo stato iniziale $q_I$ e due stati $q_A, q_B$}
  {La funzione di transizione $\delta'$ e lo stato iniziale $q_{I}'$ in seguito al collasso dello stato $q_A$ in $q_B$}
  \label{algo:hm-merge-states}
  
  $\delta' \gets \emptyset$\;
  $q_{I}' \gets q_I$\;
  \lIf{$q_I = q_A$}{
    $q_{I}' \gets q_B$
  }

  \ForEach{$(q, \sigma, q') \in \delta$}{
    \If{$q \neq q_A$}{
      \lIf{$q' = q_A$}{
        $\delta' \gets \delta' \cup \{(q, \sigma, q_B)\}$
      } 
      \lElse{
        $\delta' \gets \delta' \cup \{(q, \sigma, q')\}$
      }
    }
  }

  \Return{$(\delta', q_{I}')$}\;
\end{algo}

\begin{algo}{Algoritmo per la costruzione dell'automa iperminimo.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$, l'insieme
  quoziente $\partitioned{Q}{\sim}$ e l'insieme $K(A)$}
  {Al termine dell'esecuzione dell'algoritmo, $A$ sarà iperminimo}
  \label{algo:hm-hmdfa-build}

  \ForEach{$Q_i \in \partitioned{Q}{\sim}$}{
    $q \gets \text{un elemento qualunque di } Q_i$\;
    \If{$K(A) \cap Q_i \neq \emptyset$ and $q \notin K(A)$}{
      $q \gets \text{un elemento qualunque di } K(A) \cap Q_i$\;
    }
    \lForEach{$q' \in Q_i \setminus K(A)$}{
      $\delta, q_I \gets merge(\delta, q_I, q, q')$
    }
  }
\end{algo}

Ulteriormente, negli algoritmi che si avvalgono dell'utilizzo di tabelle hash, si assume
che tali strutture implementino alcune funzioni necessarie al loro utilizzo i cui dettagli
implementativi non sono riportati.
In particolare, la funzione \emph{containsKey} restituisce il valore booleano $true$ se la chiave passata come
argomento è presente nella tabella hash, $false$ altrimenti. La funzione \emph{deleteKey} rimuove la chiave
passata come argomento, e conseguentemente il valore ad essa associato, dalla tabella hash. Infine, 
la funzione \emph{values} restituisce la lista dei valori associati alle chiavi presenti in tabella.

\begin{algo}{Algoritmo di Tarjan per l'identificazione degli stati kernel.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$, uno stato $q \in Q$,
  tabelle hash $index$ e $low$ che associano $q \in Q$ a $n \in \mathbb{N}$, un intero $i$, uno stack $S$,
  l'insieme $K$ nel quale vengono inseriti gli stati kernel}
  {Al termine dell'esecuzione dell'algoritmo, l'insieme $K$ conterrà $K(A)$}
  \label{algo:hm-tarjan}

  $index[q], low[q] \gets i, i$\;
  $i \gets i + 1$\;
  $S.push(q)$\;

  \ForEach{$\sigma \in \Sigma$}{
    \If{not $index.containsKey(\delta(q, \sigma))$}{
      $tarjan(A, \delta(q, \sigma), index, low, i, S, C)$ \Comment*[r]{chiamata ricorsiva}
      $low[q] \gets min(low[q], low[\delta(q, \sigma)])$\;
    }
    \ElseIf{$\delta(q, \sigma) \in S$}{
      $low[q] \gets min(low[q], index[\delta(q, \sigma)])$\;
    }

    \If{$\delta(q, \sigma) = q$}{
      $K \gets K \cup \{ q \}$\;
    }
  }

  \If{$low[q] = index[q]$}{
    $scc \gets \emptyset$\;
    \While{$S.top() \neq q$}{
      $scc \gets scc \cup \{ S.pop() \}$\;
    }
    $scc \gets scc \cup \{ S.pop() \}$\;

    \If{$||scc|| > 1$}{
      $q_{scc} \gets \text{un elemento qualunque di } scc$\;
      $V \gets depthFirstSearch(A, q_{scc})$\;
      $K \gets K \cup V$\;
    }
  }
\end{algo}

L'Algoritmo \ref{algo:hm-tarjan} corrisponde alla versione semplificata dell'algoritmo di Tarjan \parencite{DFI08} per
la ricerca delle componenti fortemente connesse in un grafo introdotta nella descrizione dell'algoritmo di 
iperminimizzazione di Holzer e Maletti. In particolare, l'algoritmo è stato modificato per adattarlo
all'identificazione degli stati centrali in un automa a stati finiti deterministico minimizzato.

\begin{algo}{Algoritmo per il calcolo delle classi di quasi-equivalenza.}
  {Un automa a stati finiti deterministico minimo $A = (Q, \Sigma, \delta, q_I, F)$}
  {L'insieme quoziente $\partitioned{Q}{\sim}$}
  \label{algo:hm-almost-equivalence-classes}

  $I = Q$\;
  $P = Q$\;
  $\delta_\sim, q_{I_\sim} = \delta, q_I$\;

  $H = \text{tabella hash vuota che associa vettori di successori a stati}$

  $R = \text{tabella hash vuota che associa ad uno stato la parte di cui è elemento}$\;

  \ForEach{$q \in Q$} {
    $R[q] = \{q\}$
  }
  
  \While{$I \neq \emptyset$}{
    $q_A = \text{un elemento qualunque di } I$\;
    $I = I \setminus \{q_A\}$\;

    \If{$q_A \in P$ and $H.containsKey(V(q_A))$}{
      $q_B = H[V(q_A)]$\;

      \If{$||R[q_B]|| \geq ||R[q_A]||$}{
        $q_A, q_B = q_B, q_A$
      }

      $P = P \setminus \{q_B\}$\;
      $I = I \cup \{q \in P \ | \ \exists \sigma \in \Sigma : \delta_\sim(q, \sigma) = q_B \}$\;

      $\delta_\sim, q_{I_\sim} = merge(\delta_\sim, q_{I_\sim}, q_A, q_B)$\;

      $R[q_A] = R[q_A] \cup R[q_B]$\;
      $R.deleteKey(q_B)$
    }

    $H[V(q_A)] = q_A$\;
  }

  \Return{$R.values()$}\;
\end{algo}

% CHAPTER 4

\chapter{Risultati sperimentali}
\label{cap4}

\section{Ambiente e scelte implementative}

La prima fase del progetto è consistita nell'individuazione dell'ambiente di sviluppo e degli strumenti ad esso
annessi più adatti all'implementazione degli algoritmi di iperminimizzazione e all'analisi delle relative prestazioni.
Un attento studio delle possibilità offerte dai diversi linguaggi di programmazione general purpose e
delle librerie messe a disposizione dall'ampia community open-source ha portato alla
scelta di \emph{Python 3.12.3} \parencite{Python} come linguaggio principale per lo sviluppo del progetto.

Nel dettaglio, si è fatto ampio uso delle strutture dati offerte dalla libreria standard di Python e 
di alcune librerie di terze parti per la manipolazione di automi a stati finiti deterministici e per la 
manipolazione dei dati ottenuti dai test effettuati. In particolare, è stata utilzzata la 
libreria \emph{Automata} \parencite{Automata} per gestire i DFA all'interno del codice. Questa
è stata scelta poiché implementa già al suo interno l'algoritmo di minimizzazione di Hopcroft e permette la
rappresentazione degli automi sotto forma di grafi usando il popolare strumento di visualizzazione 
\emph{Graphviz} \parencite{Graphviz}.

\section{Generazione del campione}
\label{sec:sample-generation}

Si rende necessario comporre un campione di automi a stati finiti deterministici su cui effettuare i test
per valutare le prestazioni degli algoritmi di iperminimizzazione implementati. Poiché non sono stati trovati
dataset di DFA in letteratura che soddisfino i requisiti richiesti,
si è optato per la generazione pseudo casuale del campione.

Seguendo quanto detto, si è dovuto trovare una strategia per generare automi a stati finiti deterministici
che potessero essere iperminimizzati. Infatti, la generazione totalmente pseudo casuale porta nella stragrande
maggioranza dei casi alla generazione di automi già iperminimi.
L'idea alla base della generazione del campione è stata quella di costruire automi a stati finiti deterministici
con un alfabeto binario fissato $\Sigma = \{a, b\}$ ed il cui insieme di stati preambolo sia generato in maniera
regolare mentre l'insieme di stati kernel sia generato in modo pseudo casuale. Successivamente, si sono svolti 
dei test variando alcuni parametri per ottenere i settaggi ottimali per massimizzare la percentuale di automi
iperminimizzabili su quelli generati.

Nel dettaglio, il preambolo viene generato in modo tale che stati e transizioni formino una griglia. Suppondendo di
voler generare un preambolo composto da $n$ stati, con $n \in \mathbb{N}$, in primo luogo si compone 
una matrice di $\lfloor \sqrt{n} \rfloor$ righe e $\lfloor \sqrt{n} \rfloor$ colonne, cioè 
di $m = ( \lfloor \sqrt{n} \rfloor )^2$ elementi, in cui ogni elemento 
corrisponde ad uno stato del preambolo. Sia $q_{i,j}$ lo stato di riga $i$ e colonna $j$, lo stato iniziale
dell'automa sarà $q_{1,1}$, ovvero lo stato che si trova nella prima colonna della prima riga della matrice.
La funzione di transizione è definita $\forall q_{i,j} \text{ con } i < \sqrt{m} \text{ e } j < \sqrt{m}$ e 
$\forall \sigma \in \Sigma$, ricordando $\Sigma = \{a, b\}$, come segue:

\begin{equation*}
  \delta(q_{i,j}, \sigma) =
  \begin{cases}
    q_{i+1,j} & \text{se } \sigma = a \\
    q_{1,j+1} & \text{se } \sigma = b \\
  \end{cases}
\end{equation*}

Se $n$ non è un quadrato perfetto (i.e. $\sqrt{n} \notin \mathbb{N}$), gli $n - m$ stati preambolo rimanenti 
vengono suddivisi in due gruppi $R$ e $B$, rispettivamente di dimensione $r = \lfloor \frac{n - m}{2} \rfloor$ e 
$b = \lceil \frac{n - m}{2} \rceil$. Partendo dalla matrice costruita in precedenza, siano $q_{r_i}$ l'$i$-esimo elemento 
del gruppo $R$ e $q_{b_j}$ il $j$-esimo elemento del gruppo $B$, si completa la costruzione della griglia degli
stati preambolo come segue: $\forall i \in \{1, 2, ..., r\}, \ \delta(q_{i, \sqrt{m}}, a) = q_{r_i}$ e 
$\forall j \in \{1, 2, ..., b\}, \ \delta(q_{\sqrt{m}, j}, b) = q_{b_i}$. In altri termini, viene aggiunta una colonna
sulla destra contentente gli stati in $R$ ed una riga sotto contentente gli stati in $B$.

\begin{figure}[!htb]
  \begin{subfigure}[h]{0.39\linewidth}
    \includegraphics[width=\linewidth]{images/p_gen_dfa.png}
    \caption{Preambolo di dimensione $n=7$}
  \end{subfigure}
  \hfill
  \begin{subfigure}[h]{0.5\linewidth}
    \includegraphics[width=\linewidth]{images/perf_square_p_gen_dfa.png}
    \caption{Preambolo di dimensione $n=9$}
  \end{subfigure}
  \caption{Due esempi di preamboli generati seguendo la tecnica descritta: \\
  (a) con un numero di stati non quadrato perfetto, \\(b) con un numero quadrato perfetto di stati.}
\end{figure}

Si osservi come la funzione di transizione risultante sia parziale in quanto non è definita per tutti i simboli in ingresso
per tutti gli stati del preambolo. Nello specifico, non è definita per gli stati in ultima posizione
di ogni riga che ricevono in ingresso il simbolo $a$ e per gli stati in ultima riga che ricevono in 
ingresso il simbolo $b$. Queste transizioni sono sfruttate e sono successivamente definite in modo da 
portare gli stati preambolo agli stati kernel.

L'insieme di stati kernel può essere invece generato in due modi differenti, che ne modificano la composizione,
il che costituisce uno dei parametri che sono stati variati per ottenere i settaggi ottimali per massimizzare
la percentuale di automi iperminimizzabili su quelli generati. In particolare, il kernel può essere composto da
una singola componente fortemente connessa oppure da un numero pseudo-casuale, ovviamente minore del numero
di stati kernel, di componenti fortemente connesse, connesse tra loro.
La strategia per la generazione della singola componente fortemente connessa, supponendo di voler generare una
componente composta da $n$ stati, con $n \in \mathbb{N}$, consiste nel definire la 
funzione di transizione per il generico stato $q_i$, corrispondente all'$i$-esimo stato della componente, come
segue: $\delta(q_i, a) = q_{(i+1) \!\! \mod n}$ e $\delta(q_i, b)$ invece uguale ad uno stato scelto 
pseudo-casualmente tra quelli della componente. Il numero di stati all'interno del kernel facenti parte dell'insieme degli
stati finali è anch'esso un parametro variabile, la scelta di quali stati siano finali è invece pseudo casuale.

Infine, la connessione tra gli stati preambolo e gli stati kernel avviene in maniera pseudo-casuale: per ogni
stato preambolo $q_A$ descritto precedentemente di cui non è stata definita la transizione per un simbolo
$\sigma \in \Sigma$, si sceglie uno stato kernel $q_B$ e si definisce la transizione $\delta(q_A, \sigma) = q_B$.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.8\linewidth]{images/gen_dfa.png}
  \caption{\label{fig:gen-dfa}Un esempio di automa generato dalla procedura descritta.}
\end{figure}

Un esempio di un automa a stati finiti deterministico $A$, generato seguendo la procedura descritta,
con $||P(A)|| = 10$, $||K(A)|| = 2$ e kernel composto da una singola componente fortemente connessa,
è mostrato in Figura \ref{fig:gen-dfa}.

Come già accennato precedentemente, sono stati effettuati dei test variando alcuni parametri della
procedura di generazione, i cui risultati ottenuti sono riportati di seguito, al fine di ottenere i
settaggi ottimali per massimizzare la percentuale di automi iperminimizzabili su
quelli generati. Maggiormente nello specifico, sono stati variati: il rapporto tra gli stati
preambolo e gli stati kernel, la percentuale di stati kernel finali, la composizione
del kernel e il numero di stati dell'automa.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/dfa_gen_fstates_nstates.png}
  \caption{\label{fig:dfa-gen-fstates-nstates}Efficacia dell'iperminimizzazione 
  su automi con differente\\numero di stati kernel finali e numero di stati.}
\end{figure}

La Figura \ref{fig:dfa-gen-fstates-nstates} mostra come varia l'efficacia dell'iperminimizzazione 
su automi con differente numero di stati kernel finali all'aumentare del numero di stati dell'automa.
Se ne deduce che, nonostante all'aumentare del numero di stati diminuisca la percentuale di automi
iperminimizzabili, automi con un kernel composto da più di una componente fortemente connessa e con un alto
numero di stati finali nel kernel sono più proni all'essere iperminimizzati.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/dfa_gen_fstates_pstates.png}
  \caption{\label{fig:dfa-gen-fstates-pstates}Efficacia dell'iperminimizzazione 
  su automi con differente numero di\\stati kernel finali e rapporto tra stati preambolo e kernel.}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/dfa_gen_pstates_nstates.png}
  \caption{\label{fig:dfa-gen-pstates-nstates}Efficacia dell'iperminimizzazione 
  su automi con differente numero di stati e rapporto tra stati preambolo e kernel.}
\end{figure}

In Figura \ref{fig:dfa-gen-fstates-pstates} è possibile osservare come varia l'efficacia dell'iperminimizzazione 
su automi con differente numero di stati kernel finali all'aumentare del rapporto tra stati preambolo e kernel.
Risulta chiaro che automi con un kernel composto da più di una componente fortemente connessa e con kernel di 
dimensioni ridotte contenente un alto numero di stati finali sono più probabilmente iperminimizzabili.

La Figura \ref{fig:dfa-gen-pstates-nstates} mostra come varia l'efficacia dell'iperminimizzazione 
su automi con differente rapporto tra stati preambolo e kernel all'aumentare del numero di stati dell'automa.
Si osservi come, ancora una volta, nonostante all'aumentare del numero di stati diminuisca la percentuale di automi
iperminimizzabili, automi con un kernel composto da più di una componente fortemente connessa e con un alto
numero di stati preambolo e basso numero di stati kernel sono più proni all'essere iperminimizzati.

In conclusione, risulta chiaro che, per massimizzare la percentuale di automi generati iperminimizzabili,
è necessario generare automi con un kernel composto da più di una componente fortemente connessa, con un alto
numero di stati finali nel kernel e con un rapporto tra stati preambolo e kernel che favorisca nettamente
gli stati preambolo.

\section{Prestazioni}

È stata effettuata una serie di test sperimentali per valutare le prestazioni degli algoritmi di iperminimizzazione
implementati. Gli esperimenti sono stati condotti su una macchina con processore Apple M1, 16GB di RAM e sistema
operativo macOS Sonoma 14.5 e su di un campione di automi generati come descritto precedentemente con un numero di
stati compreso tra $2^2$ e $2^{10}$, in particolar modo 256 automi per ogni potenza di $2$ inclusa nell'intervallo
(estremi inclusi), in modo tale da osservare come il tempo di esecuzione di ciascun algoritmo varia in relazione
alla dimensione, in termini di numero di stati, dell’automa in ingresso.

Sulla base dei risultati ottenuti nella Sezione \ref{sec:sample-generation}, sono stati generati automi
con un rapporto tra stati preambolo e kernel che favorisca nettamente gli stati preambolo,
pari a $0.8$, e con un kernel formato da più di una componente fortemente connessa nel quale
l'$80\%$ degli stati da cui è composto appartenga all'insieme degli stati finali.

Gli esiti ottenuti dagli esperimenti sono riportati in Figura \ref{fig:dfa-pcomparison-all-lines}, 
\ref{fig:dfa-pcomparison-only-lines} e \ref{fig:dfa-pcomparison-violin}.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/performance_all_line.png}
  \caption{\label{fig:dfa-pcomparison-all-lines}Performance degli algoritmi di iperminimizzazione sull'intero campione.}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/performance_filtered_line.png}
  \caption{\label{fig:dfa-pcomparison-only-lines}Performance degli algoritmi di iperminimizzazione sul
  campione considerando solo gli automi iperminimizzazati diversi dell'automa minimo.}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/performance_violin.png}
  \caption{\label{fig:dfa-pcomparison-violin}Distribuzioni delle performance degli algoritmi di iperminimizzazione.}
\end{figure}

I risultati sperimentali confermano le aspettative per quanto riguarda le prestazioni dell'algoritmo di Holzer e Maletti,
che risulta essere il più efficiente tra quelli implementati, mentre smentiscono
parzialmente le aspettative per quanto riguarda gli altri due algoritmi. Infatti, l'algoritmo di Badr risulta
essere più lento dell'algoritmo di Badr, Geffert e Shipman. Questo risultato è dovuto al fatto che 
l'algoritmo di Badr, nella funzione che si occupa della costruzione dello XOR cross product dell'automa in
ingresso minimizzato con se stesso ed in quella che effettua calcolo degli stati che inducono un linguaggio
finito su quest'ultimo, effettua $\Theta(n^2)$ operazioni, dove $n$ è il numero di stati dell'automa in ingresso, il che significa che eseguirà sempre esattamente 
un numero di operazioni nell'ordine di $n^2$. Al contrario, l'algoritmo di Badr, Geffert e Shipman, nel calcolo delle classi di
quasi-equivalenza, effettua un numero di operazioni $\bigo(n^3 \cdot m)$, dove $m$ è il
numero di simboli dell'alfabeto dell'automa in ingresso, questo implica che l'algoritmo effettua al più
un numero di operazioni nell'ordine di $n^3 \cdot m$, ma come dimostrano i risultati sperimentali, tale caso
accade molto raramente e dunque nella pratica effettua molte meno operazioni.
Nel dettaglio, l'algoritmo di Badr, Geffert e Shipman risulta essere il più lento tra i tre algoritmi implementati
quando la ricerca delle coppie di stati quasi-equivalenti richiede tutte le $n-1$ iterazioni al massimo richieste
per trovare $\partitioned{Q}{\sim}$, il che, nuovamente, accade molto di rado. La dimostrazione di quanto detto è
osservabile in Figura \ref{fig:dfa-pcomparison-all-forced-lines}, dove è stata eseguita una versione modificata dell'algoritmo 
dove la ricerca delle coppie di stati quasi-equivalenti non termina nel momento in cui non ci sono più coppie
che soddisfino tale condizione ma continua fino a che non ha effettuato tutte le $n-1$ iterazioni, ovvero il caso
peggiore possibile.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/performance_forced_all_line.png}
  \caption{\label{fig:dfa-pcomparison-all-forced-lines}Performance degli algoritmi di iperminimizzazione sul
  campione forzando l'algoritmo di Badr, Geffert e Shipman ad eseguire $\Theta(n^3 \cdot m)$ operazioni.}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/performance_violin_focus_all.png}
  \caption{\label{fig:dfa-pcomparison-violin-focus-all}Focus sulle distribuzioni delle performance degli algoritmi
  di iperminimizzazione sull'intero campione.}
\end{figure}

\begin{figure}[!htb]
  \centering
  \includegraphics[width=1\linewidth]{images/performance_violin_focus_only.png}
  \caption{\label{fig:dfa-pcomparison-violin-focus-only}Focus sulle distribuzioni delle performance degli algoritmi
  di iperminimizzazione considerando solo gli automi il cui numero di stati in seguito all'iperminimizzazione
  è minore dell'automa minimo.}
\end{figure}

% BIBLIOGRAPHY

\defbibfilter{papers}{
  type=article or
  type=inproceedings or
  type=incollection
}

\printbibheading
\printbibliography[filter=papers,heading=subbibliography,title={Pubblicazioni}]
\printbibliography[type=book,heading=subbibliography,title={Testi}]
\printbibliography[type=software,heading=subbibliography,title={Software}]

\end{document}